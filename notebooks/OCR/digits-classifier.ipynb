{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Digits classifier\n",
    "\n",
    "Let's build a model that is able to recognize the digits 3 and 7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading and setting up dependencies\n",
    "import fastbook\n",
    "\n",
    "fastbook.setup_book()\n",
    "\n",
    "from fastai.vision.all import *\n",
    "from fastbook import *\n",
    "from matplotlib import pyplot as plt\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#3) [Path('train'),Path('labels.csv'),Path('valid')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import MNIST sample that only contains 3s and 7s\n",
    "path_to_mnist_sample = untar_data(URLs.MNIST_SAMPLE)\n",
    "Path.BASE_PATH = path_to_mnist_sample\n",
    "\n",
    "path_to_mnist_sample.ls()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see from the previous output, this dataset is organized into separate folders for training and validation sets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is also a `labels.csv` file that provides the actual label for each of the training images. We can load this into a dataframe using Pandas. This an alternative way of processing training and validation data instead of relying only on the folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train/3/7463.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train/3/21102.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train/3/31559.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train/3/46882.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train/3/26209.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                name  label\n",
       "0   train/3/7463.png      0\n",
       "1  train/3/21102.png      0\n",
       "2  train/3/31559.png      0\n",
       "3  train/3/46882.png      0\n",
       "4  train/3/26209.png      0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_sample_labels_df = pd.read_csv(path_to_mnist_sample / \"labels.csv\")\n",
    "mnist_sample_labels_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#2) [Path('train/3'),Path('train/7')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's see what's inside the training set\n",
    "(path_to_mnist_sample/'train').ls()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are confirming here that the training sample contains 7's and 3's only. These are our _labels_. Let's zoom in a little more into the folder structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#6131) [Path('train/3/10.png'),Path('train/3/10000.png'),Path('train/3/10011.png'),Path('train/3/10031.png'),Path('train/3/10034.png'),Path('train/3/10042.png'),Path('train/3/10052.png'),Path('train/3/1007.png'),Path('train/3/10074.png'),Path('train/3/10091.png')...]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_threes = (path_to_mnist_sample/'train'/'3').ls().sorted()\n",
    "mnist_sevens = (path_to_mnist_sample/'train'/'7').ls().sorted()\n",
    "mnist_threes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Images as array of numbers, e.g. tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/wAALCAAcABwBAREA/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/9oACAEBAAA/APCdP02+1a8W006znu7l+VigjLsQOpwO1dlb/CjVnkS3vNb8O6dqDkKtheaiFn3Hou1QcE8YBPcVg+LfCGqeCtYXS9WEPnvEJlML7lKEkA547qawatafqd/pN2LvTb24s7lQQJbeQowB6jI5r1D4Y6b4OvdXtdf8S+K45NY85phY3W6MeaCdrSTNw3IDcd8ZzyKx/i5pXiiLxMNZ8RC1kjvx/os1nJvh2KOFU8HgEHkc5zXntWdP0681a/hsbC3kubqY7Y4oxlmPXiu68OfBzxPq1yJNVtW0XTI/mnu73CbF74UkEn64HvVn4r+LdI1GDR/C3h2QzaTosXli5JJ858BeM9QAOvck9sV5nU1rdXFjdR3VpPLb3ETbo5YnKOh9QRyDV7UfE2v6vbi31PXNSvYA24RXN3JIufXDEjNZdFf/2Q==",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA9UlEQVR4AWNgGGSAEe4e2Upda8b/mwSvnloAF4MyDJY9+Pv31ZG/QPASTS72y8+/u/W4OFi4DiFLsoCV8XEyvCy9BGT++cfAsBlNJ7OICD9YSPvB369eaJJw7s+/X+vgHBQGX+r9vz9qUIRgHO5l74FO3S0H46PQAj9+gTzy4mo+E4o4lKOdlHQBJL9bDJssAwOncTlQ1ge7JAMD4/a/f7uhkhjm///PwHAXl87Qn3//quCQtLn29+9abuySSd///n3EiVVOa9ofYKSYostpFWvZFM//8Pfvr/WS6HIMu0GeB4KjYRhSDAzpYKkXzohUg0URtYQA/HZrR+ekLi0AAAAASUVORK5CYII=",
      "text/plain": [
       "<PIL.PngImagePlugin.PngImageFile image mode=L size=28x28>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's look at one image\n",
    "mnist_3_example = mnist_threes[1]\n",
    "ex3_numpy_array = Image.open(mnist_3_example)\n",
    "ex3_numpy_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  29, 150, 195, 254, 255, 254, 176, 193, 150,  96,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  48, 166, 224, 253, 253, 234, 196, 253, 253, 253, 253, 233,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,  93, 244, 249, 253, 187,  46,  10,   8,   4,  10, 194, 253, 253, 233,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0, 107, 253, 253, 230,  48,   0,   0,   0,   0,   0, 192, 253, 253, 156,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   3,  20,  20,  15,   0,   0,   0,   0,   0,  43, 224, 253, 245,  74,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 249, 253, 245, 126,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  14, 101, 223, 253, 248, 124,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 166, 239, 253, 253, 253, 187,  30,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  16, 248, 250, 253, 253, 253, 253, 232, 213, 111,   2,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  43,  98,  98, 208, 253, 253, 253, 253, 187,  22,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   9,  51, 119, 253, 253, 253,  76,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   1, 183, 253, 253, 139,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 182, 253, 253, 104,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  85, 249, 253, 253,  36,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  60, 214, 253, 253, 173,  11,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  98, 247, 253, 253, 226,   9,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  42, 150, 252, 253, 253, 233,  53,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,  42, 115,  42,  60, 115, 159, 240, 253, 253, 250, 175,  25,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0, 187, 253, 253, 253, 253, 253, 253, 253, 197,  86,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0, 103, 253, 253, 253, 253, 253, 232,  67,   1,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]], dtype=uint8)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# viewing the numbers that make up that image as a `NumPy` array\n",
    "array(ex3_numpy_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,  29],\n",
       "       [  0,   0,   0,  48, 166, 224],\n",
       "       [  0,  93, 244, 249, 253, 187],\n",
       "       [  0, 107, 253, 253, 230,  48],\n",
       "       [  0,   3,  20,  20,  15,   0]], dtype=uint8)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# selecting a subarray from rows 4 to 10 (not included) and columns 4 to 10 (not included)\n",
    "# `numpy` indexes from top to bottom and left to right\n",
    "array(ex3_numpy_array)[4:10,4:10] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now let's do the same thing with a `pytorch` tensor\n",
    "ex3_pytorch_tensor = tensor(ex3_numpy_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,  29],\n",
       "        [  0,   0,   0,  48, 166, 224],\n",
       "        [  0,  93, 244, 249, 253, 187],\n",
       "        [  0, 107, 253, 253, 230,  48],\n",
       "        [  0,   3,  20,  20,  15,   0]], dtype=torch.uint8)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex3_pytorch_tensor[4:10,4:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>150</td>\n",
       "      <td>195</td>\n",
       "      <td>254</td>\n",
       "      <td>255</td>\n",
       "      <td>254</td>\n",
       "      <td>176</td>\n",
       "      <td>193</td>\n",
       "      <td>150</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>48</td>\n",
       "      <td>166</td>\n",
       "      <td>224</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>234</td>\n",
       "      <td>196</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>233</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>93</td>\n",
       "      <td>244</td>\n",
       "      <td>249</td>\n",
       "      <td>253</td>\n",
       "      <td>187</td>\n",
       "      <td>46</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>194</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>233</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>107</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>230</td>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>192</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>156</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>224</td>\n",
       "      <td>253</td>\n",
       "      <td>245</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>249</td>\n",
       "      <td>253</td>\n",
       "      <td>245</td>\n",
       "      <td>126</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>101</td>\n",
       "      <td>223</td>\n",
       "      <td>253</td>\n",
       "      <td>248</td>\n",
       "      <td>124</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>166</td>\n",
       "      <td>239</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>187</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>248</td>\n",
       "      <td>250</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>232</td>\n",
       "      <td>213</td>\n",
       "      <td>111</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>98</td>\n",
       "      <td>98</td>\n",
       "      <td>208</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>187</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    0    1    2    3    4    5    6    7    8    9    10   11   12   13   14  \\\n",
       "0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0   \n",
       "1    0    0    0    0    0   29  150  195  254  255  254  176  193  150   96   \n",
       "2    0    0    0   48  166  224  253  253  234  196  253  253  253  253  233   \n",
       "3    0   93  244  249  253  187   46   10    8    4   10  194  253  253  233   \n",
       "4    0  107  253  253  230   48    0    0    0    0    0  192  253  253  156   \n",
       "5    0    3   20   20   15    0    0    0    0    0   43  224  253  245   74   \n",
       "6    0    0    0    0    0    0    0    0    0    0  249  253  245  126    0   \n",
       "7    0    0    0    0    0    0    0   14  101  223  253  248  124    0    0   \n",
       "8    0    0    0    0    0   11  166  239  253  253  253  187   30    0    0   \n",
       "9    0    0    0    0    0   16  248  250  253  253  253  253  232  213  111   \n",
       "10   0    0    0    0    0    0    0   43   98   98  208  253  253  253  253   \n",
       "\n",
       "     15  16  17  \n",
       "0     0   0   0  \n",
       "1     0   0   0  \n",
       "2     0   0   0  \n",
       "3     0   0   0  \n",
       "4     0   0   0  \n",
       "5     0   0   0  \n",
       "6     0   0   0  \n",
       "7     0   0   0  \n",
       "8     0   0   0  \n",
       "9     2   0   0  \n",
       "10  187  22   0  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's make a data frame out of the three image specimen tensor,\n",
    "# we'll only select the top part of the image\n",
    "df = pd.DataFrame(ex3_pytorch_tensor[4:15,4:22])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_33fa1_row0_col0, #T_33fa1_row0_col1, #T_33fa1_row0_col2, #T_33fa1_row0_col3, #T_33fa1_row0_col4, #T_33fa1_row0_col5, #T_33fa1_row0_col6, #T_33fa1_row0_col7, #T_33fa1_row0_col8, #T_33fa1_row0_col9, #T_33fa1_row0_col10, #T_33fa1_row0_col11, #T_33fa1_row0_col12, #T_33fa1_row0_col13, #T_33fa1_row0_col14, #T_33fa1_row0_col15, #T_33fa1_row0_col16, #T_33fa1_row0_col17, #T_33fa1_row1_col0, #T_33fa1_row1_col1, #T_33fa1_row1_col2, #T_33fa1_row1_col3, #T_33fa1_row1_col4, #T_33fa1_row1_col15, #T_33fa1_row1_col16, #T_33fa1_row1_col17, #T_33fa1_row2_col0, #T_33fa1_row2_col1, #T_33fa1_row2_col2, #T_33fa1_row2_col15, #T_33fa1_row2_col16, #T_33fa1_row2_col17, #T_33fa1_row3_col0, #T_33fa1_row3_col15, #T_33fa1_row3_col16, #T_33fa1_row3_col17, #T_33fa1_row4_col0, #T_33fa1_row4_col6, #T_33fa1_row4_col7, #T_33fa1_row4_col8, #T_33fa1_row4_col9, #T_33fa1_row4_col10, #T_33fa1_row4_col15, #T_33fa1_row4_col16, #T_33fa1_row4_col17, #T_33fa1_row5_col0, #T_33fa1_row5_col5, #T_33fa1_row5_col6, #T_33fa1_row5_col7, #T_33fa1_row5_col8, #T_33fa1_row5_col9, #T_33fa1_row5_col15, #T_33fa1_row5_col16, #T_33fa1_row5_col17, #T_33fa1_row6_col0, #T_33fa1_row6_col1, #T_33fa1_row6_col2, #T_33fa1_row6_col3, #T_33fa1_row6_col4, #T_33fa1_row6_col5, #T_33fa1_row6_col6, #T_33fa1_row6_col7, #T_33fa1_row6_col8, #T_33fa1_row6_col9, #T_33fa1_row6_col14, #T_33fa1_row6_col15, #T_33fa1_row6_col16, #T_33fa1_row6_col17, #T_33fa1_row7_col0, #T_33fa1_row7_col1, #T_33fa1_row7_col2, #T_33fa1_row7_col3, #T_33fa1_row7_col4, #T_33fa1_row7_col5, #T_33fa1_row7_col6, #T_33fa1_row7_col13, #T_33fa1_row7_col14, #T_33fa1_row7_col15, #T_33fa1_row7_col16, #T_33fa1_row7_col17, #T_33fa1_row8_col0, #T_33fa1_row8_col1, #T_33fa1_row8_col2, #T_33fa1_row8_col3, #T_33fa1_row8_col4, #T_33fa1_row8_col13, #T_33fa1_row8_col14, #T_33fa1_row8_col15, #T_33fa1_row8_col16, #T_33fa1_row8_col17, #T_33fa1_row9_col0, #T_33fa1_row9_col1, #T_33fa1_row9_col2, #T_33fa1_row9_col3, #T_33fa1_row9_col4, #T_33fa1_row9_col16, #T_33fa1_row9_col17, #T_33fa1_row10_col0, #T_33fa1_row10_col1, #T_33fa1_row10_col2, #T_33fa1_row10_col3, #T_33fa1_row10_col4, #T_33fa1_row10_col5, #T_33fa1_row10_col6, #T_33fa1_row10_col17 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #ffffff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_33fa1_row1_col5 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #efefef;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_33fa1_row1_col6, #T_33fa1_row1_col13 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #7c7c7c;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_33fa1_row1_col7 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #4a4a4a;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_33fa1_row1_col8, #T_33fa1_row1_col9, #T_33fa1_row1_col10, #T_33fa1_row2_col5, #T_33fa1_row2_col6, #T_33fa1_row2_col7, #T_33fa1_row2_col11, #T_33fa1_row2_col12, #T_33fa1_row2_col13, #T_33fa1_row3_col4, #T_33fa1_row3_col12, #T_33fa1_row3_col13, #T_33fa1_row4_col1, #T_33fa1_row4_col2, #T_33fa1_row4_col3, #T_33fa1_row4_col12, #T_33fa1_row4_col13, #T_33fa1_row5_col12, #T_33fa1_row6_col11, #T_33fa1_row9_col11, #T_33fa1_row10_col11, #T_33fa1_row10_col12, #T_33fa1_row10_col13, #T_33fa1_row10_col14, #T_33fa1_row10_col15, #T_33fa1_row10_col16 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #000000;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_33fa1_row1_col11 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #606060;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_33fa1_row1_col12 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #4d4d4d;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_33fa1_row1_col14 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #bbbbbb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_33fa1_row2_col3 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #e4e4e4;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_33fa1_row2_col4, #T_33fa1_row8_col6 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #6b6b6b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_33fa1_row2_col8, #T_33fa1_row2_col14, #T_33fa1_row3_col14 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #171717;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_33fa1_row2_col9, #T_33fa1_row3_col11 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #4b4b4b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_33fa1_row2_col10, #T_33fa1_row7_col10, #T_33fa1_row8_col8, #T_33fa1_row8_col10, #T_33fa1_row9_col8, #T_33fa1_row9_col10 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #010101;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_33fa1_row3_col1 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #272727;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_33fa1_row3_col2 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #0a0a0a;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_33fa1_row3_col3 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #050505;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_33fa1_row3_col5 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #333333;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_33fa1_row3_col6 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #e6e6e6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_33fa1_row3_col7, #T_33fa1_row3_col10 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #fafafa;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_33fa1_row3_col8 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #fbfbfb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_33fa1_row3_col9 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #fdfdfd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_33fa1_row4_col4 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #1b1b1b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_33fa1_row4_col5 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #e0e0e0;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_33fa1_row4_col11 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #4e4e4e;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_33fa1_row4_col14 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #767676;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_33fa1_row5_col1 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #fcfcfc;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_33fa1_row5_col2, #T_33fa1_row5_col3 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #f6f6f6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_33fa1_row5_col4, #T_33fa1_row7_col7 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #f8f8f8;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_33fa1_row5_col10, #T_33fa1_row10_col7 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #e8e8e8;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_33fa1_row5_col11 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #222222;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_33fa1_row5_col13, #T_33fa1_row6_col12 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #090909;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_33fa1_row5_col14 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #d0d0d0;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_33fa1_row6_col10, #T_33fa1_row7_col11, #T_33fa1_row9_col6 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #060606;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_33fa1_row6_col13 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #979797;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_33fa1_row7_col8 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #b6b6b6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_33fa1_row7_col9 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #252525;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_33fa1_row7_col12 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #999999;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_33fa1_row8_col5 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #f9f9f9;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_33fa1_row8_col7 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #101010;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_33fa1_row8_col9, #T_33fa1_row9_col9 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #020202;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_33fa1_row8_col11 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #545454;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_33fa1_row8_col12 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #f1f1f1;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_33fa1_row9_col5 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #f7f7f7;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_33fa1_row9_col7 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #030303;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_33fa1_row9_col12 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #181818;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_33fa1_row9_col13 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #303030;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_33fa1_row9_col14 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #a9a9a9;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_33fa1_row9_col15 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #fefefe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_33fa1_row10_col8, #T_33fa1_row10_col9 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #bababa;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_33fa1_row10_col10 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #393939;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_33fa1\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_33fa1_level0_col0\" class=\"col_heading level0 col0\" >0</th>\n",
       "      <th id=\"T_33fa1_level0_col1\" class=\"col_heading level0 col1\" >1</th>\n",
       "      <th id=\"T_33fa1_level0_col2\" class=\"col_heading level0 col2\" >2</th>\n",
       "      <th id=\"T_33fa1_level0_col3\" class=\"col_heading level0 col3\" >3</th>\n",
       "      <th id=\"T_33fa1_level0_col4\" class=\"col_heading level0 col4\" >4</th>\n",
       "      <th id=\"T_33fa1_level0_col5\" class=\"col_heading level0 col5\" >5</th>\n",
       "      <th id=\"T_33fa1_level0_col6\" class=\"col_heading level0 col6\" >6</th>\n",
       "      <th id=\"T_33fa1_level0_col7\" class=\"col_heading level0 col7\" >7</th>\n",
       "      <th id=\"T_33fa1_level0_col8\" class=\"col_heading level0 col8\" >8</th>\n",
       "      <th id=\"T_33fa1_level0_col9\" class=\"col_heading level0 col9\" >9</th>\n",
       "      <th id=\"T_33fa1_level0_col10\" class=\"col_heading level0 col10\" >10</th>\n",
       "      <th id=\"T_33fa1_level0_col11\" class=\"col_heading level0 col11\" >11</th>\n",
       "      <th id=\"T_33fa1_level0_col12\" class=\"col_heading level0 col12\" >12</th>\n",
       "      <th id=\"T_33fa1_level0_col13\" class=\"col_heading level0 col13\" >13</th>\n",
       "      <th id=\"T_33fa1_level0_col14\" class=\"col_heading level0 col14\" >14</th>\n",
       "      <th id=\"T_33fa1_level0_col15\" class=\"col_heading level0 col15\" >15</th>\n",
       "      <th id=\"T_33fa1_level0_col16\" class=\"col_heading level0 col16\" >16</th>\n",
       "      <th id=\"T_33fa1_level0_col17\" class=\"col_heading level0 col17\" >17</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_33fa1_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_33fa1_row0_col0\" class=\"data row0 col0\" >0</td>\n",
       "      <td id=\"T_33fa1_row0_col1\" class=\"data row0 col1\" >0</td>\n",
       "      <td id=\"T_33fa1_row0_col2\" class=\"data row0 col2\" >0</td>\n",
       "      <td id=\"T_33fa1_row0_col3\" class=\"data row0 col3\" >0</td>\n",
       "      <td id=\"T_33fa1_row0_col4\" class=\"data row0 col4\" >0</td>\n",
       "      <td id=\"T_33fa1_row0_col5\" class=\"data row0 col5\" >0</td>\n",
       "      <td id=\"T_33fa1_row0_col6\" class=\"data row0 col6\" >0</td>\n",
       "      <td id=\"T_33fa1_row0_col7\" class=\"data row0 col7\" >0</td>\n",
       "      <td id=\"T_33fa1_row0_col8\" class=\"data row0 col8\" >0</td>\n",
       "      <td id=\"T_33fa1_row0_col9\" class=\"data row0 col9\" >0</td>\n",
       "      <td id=\"T_33fa1_row0_col10\" class=\"data row0 col10\" >0</td>\n",
       "      <td id=\"T_33fa1_row0_col11\" class=\"data row0 col11\" >0</td>\n",
       "      <td id=\"T_33fa1_row0_col12\" class=\"data row0 col12\" >0</td>\n",
       "      <td id=\"T_33fa1_row0_col13\" class=\"data row0 col13\" >0</td>\n",
       "      <td id=\"T_33fa1_row0_col14\" class=\"data row0 col14\" >0</td>\n",
       "      <td id=\"T_33fa1_row0_col15\" class=\"data row0 col15\" >0</td>\n",
       "      <td id=\"T_33fa1_row0_col16\" class=\"data row0 col16\" >0</td>\n",
       "      <td id=\"T_33fa1_row0_col17\" class=\"data row0 col17\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_33fa1_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_33fa1_row1_col0\" class=\"data row1 col0\" >0</td>\n",
       "      <td id=\"T_33fa1_row1_col1\" class=\"data row1 col1\" >0</td>\n",
       "      <td id=\"T_33fa1_row1_col2\" class=\"data row1 col2\" >0</td>\n",
       "      <td id=\"T_33fa1_row1_col3\" class=\"data row1 col3\" >0</td>\n",
       "      <td id=\"T_33fa1_row1_col4\" class=\"data row1 col4\" >0</td>\n",
       "      <td id=\"T_33fa1_row1_col5\" class=\"data row1 col5\" >29</td>\n",
       "      <td id=\"T_33fa1_row1_col6\" class=\"data row1 col6\" >150</td>\n",
       "      <td id=\"T_33fa1_row1_col7\" class=\"data row1 col7\" >195</td>\n",
       "      <td id=\"T_33fa1_row1_col8\" class=\"data row1 col8\" >254</td>\n",
       "      <td id=\"T_33fa1_row1_col9\" class=\"data row1 col9\" >255</td>\n",
       "      <td id=\"T_33fa1_row1_col10\" class=\"data row1 col10\" >254</td>\n",
       "      <td id=\"T_33fa1_row1_col11\" class=\"data row1 col11\" >176</td>\n",
       "      <td id=\"T_33fa1_row1_col12\" class=\"data row1 col12\" >193</td>\n",
       "      <td id=\"T_33fa1_row1_col13\" class=\"data row1 col13\" >150</td>\n",
       "      <td id=\"T_33fa1_row1_col14\" class=\"data row1 col14\" >96</td>\n",
       "      <td id=\"T_33fa1_row1_col15\" class=\"data row1 col15\" >0</td>\n",
       "      <td id=\"T_33fa1_row1_col16\" class=\"data row1 col16\" >0</td>\n",
       "      <td id=\"T_33fa1_row1_col17\" class=\"data row1 col17\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_33fa1_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_33fa1_row2_col0\" class=\"data row2 col0\" >0</td>\n",
       "      <td id=\"T_33fa1_row2_col1\" class=\"data row2 col1\" >0</td>\n",
       "      <td id=\"T_33fa1_row2_col2\" class=\"data row2 col2\" >0</td>\n",
       "      <td id=\"T_33fa1_row2_col3\" class=\"data row2 col3\" >48</td>\n",
       "      <td id=\"T_33fa1_row2_col4\" class=\"data row2 col4\" >166</td>\n",
       "      <td id=\"T_33fa1_row2_col5\" class=\"data row2 col5\" >224</td>\n",
       "      <td id=\"T_33fa1_row2_col6\" class=\"data row2 col6\" >253</td>\n",
       "      <td id=\"T_33fa1_row2_col7\" class=\"data row2 col7\" >253</td>\n",
       "      <td id=\"T_33fa1_row2_col8\" class=\"data row2 col8\" >234</td>\n",
       "      <td id=\"T_33fa1_row2_col9\" class=\"data row2 col9\" >196</td>\n",
       "      <td id=\"T_33fa1_row2_col10\" class=\"data row2 col10\" >253</td>\n",
       "      <td id=\"T_33fa1_row2_col11\" class=\"data row2 col11\" >253</td>\n",
       "      <td id=\"T_33fa1_row2_col12\" class=\"data row2 col12\" >253</td>\n",
       "      <td id=\"T_33fa1_row2_col13\" class=\"data row2 col13\" >253</td>\n",
       "      <td id=\"T_33fa1_row2_col14\" class=\"data row2 col14\" >233</td>\n",
       "      <td id=\"T_33fa1_row2_col15\" class=\"data row2 col15\" >0</td>\n",
       "      <td id=\"T_33fa1_row2_col16\" class=\"data row2 col16\" >0</td>\n",
       "      <td id=\"T_33fa1_row2_col17\" class=\"data row2 col17\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_33fa1_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_33fa1_row3_col0\" class=\"data row3 col0\" >0</td>\n",
       "      <td id=\"T_33fa1_row3_col1\" class=\"data row3 col1\" >93</td>\n",
       "      <td id=\"T_33fa1_row3_col2\" class=\"data row3 col2\" >244</td>\n",
       "      <td id=\"T_33fa1_row3_col3\" class=\"data row3 col3\" >249</td>\n",
       "      <td id=\"T_33fa1_row3_col4\" class=\"data row3 col4\" >253</td>\n",
       "      <td id=\"T_33fa1_row3_col5\" class=\"data row3 col5\" >187</td>\n",
       "      <td id=\"T_33fa1_row3_col6\" class=\"data row3 col6\" >46</td>\n",
       "      <td id=\"T_33fa1_row3_col7\" class=\"data row3 col7\" >10</td>\n",
       "      <td id=\"T_33fa1_row3_col8\" class=\"data row3 col8\" >8</td>\n",
       "      <td id=\"T_33fa1_row3_col9\" class=\"data row3 col9\" >4</td>\n",
       "      <td id=\"T_33fa1_row3_col10\" class=\"data row3 col10\" >10</td>\n",
       "      <td id=\"T_33fa1_row3_col11\" class=\"data row3 col11\" >194</td>\n",
       "      <td id=\"T_33fa1_row3_col12\" class=\"data row3 col12\" >253</td>\n",
       "      <td id=\"T_33fa1_row3_col13\" class=\"data row3 col13\" >253</td>\n",
       "      <td id=\"T_33fa1_row3_col14\" class=\"data row3 col14\" >233</td>\n",
       "      <td id=\"T_33fa1_row3_col15\" class=\"data row3 col15\" >0</td>\n",
       "      <td id=\"T_33fa1_row3_col16\" class=\"data row3 col16\" >0</td>\n",
       "      <td id=\"T_33fa1_row3_col17\" class=\"data row3 col17\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_33fa1_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_33fa1_row4_col0\" class=\"data row4 col0\" >0</td>\n",
       "      <td id=\"T_33fa1_row4_col1\" class=\"data row4 col1\" >107</td>\n",
       "      <td id=\"T_33fa1_row4_col2\" class=\"data row4 col2\" >253</td>\n",
       "      <td id=\"T_33fa1_row4_col3\" class=\"data row4 col3\" >253</td>\n",
       "      <td id=\"T_33fa1_row4_col4\" class=\"data row4 col4\" >230</td>\n",
       "      <td id=\"T_33fa1_row4_col5\" class=\"data row4 col5\" >48</td>\n",
       "      <td id=\"T_33fa1_row4_col6\" class=\"data row4 col6\" >0</td>\n",
       "      <td id=\"T_33fa1_row4_col7\" class=\"data row4 col7\" >0</td>\n",
       "      <td id=\"T_33fa1_row4_col8\" class=\"data row4 col8\" >0</td>\n",
       "      <td id=\"T_33fa1_row4_col9\" class=\"data row4 col9\" >0</td>\n",
       "      <td id=\"T_33fa1_row4_col10\" class=\"data row4 col10\" >0</td>\n",
       "      <td id=\"T_33fa1_row4_col11\" class=\"data row4 col11\" >192</td>\n",
       "      <td id=\"T_33fa1_row4_col12\" class=\"data row4 col12\" >253</td>\n",
       "      <td id=\"T_33fa1_row4_col13\" class=\"data row4 col13\" >253</td>\n",
       "      <td id=\"T_33fa1_row4_col14\" class=\"data row4 col14\" >156</td>\n",
       "      <td id=\"T_33fa1_row4_col15\" class=\"data row4 col15\" >0</td>\n",
       "      <td id=\"T_33fa1_row4_col16\" class=\"data row4 col16\" >0</td>\n",
       "      <td id=\"T_33fa1_row4_col17\" class=\"data row4 col17\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_33fa1_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_33fa1_row5_col0\" class=\"data row5 col0\" >0</td>\n",
       "      <td id=\"T_33fa1_row5_col1\" class=\"data row5 col1\" >3</td>\n",
       "      <td id=\"T_33fa1_row5_col2\" class=\"data row5 col2\" >20</td>\n",
       "      <td id=\"T_33fa1_row5_col3\" class=\"data row5 col3\" >20</td>\n",
       "      <td id=\"T_33fa1_row5_col4\" class=\"data row5 col4\" >15</td>\n",
       "      <td id=\"T_33fa1_row5_col5\" class=\"data row5 col5\" >0</td>\n",
       "      <td id=\"T_33fa1_row5_col6\" class=\"data row5 col6\" >0</td>\n",
       "      <td id=\"T_33fa1_row5_col7\" class=\"data row5 col7\" >0</td>\n",
       "      <td id=\"T_33fa1_row5_col8\" class=\"data row5 col8\" >0</td>\n",
       "      <td id=\"T_33fa1_row5_col9\" class=\"data row5 col9\" >0</td>\n",
       "      <td id=\"T_33fa1_row5_col10\" class=\"data row5 col10\" >43</td>\n",
       "      <td id=\"T_33fa1_row5_col11\" class=\"data row5 col11\" >224</td>\n",
       "      <td id=\"T_33fa1_row5_col12\" class=\"data row5 col12\" >253</td>\n",
       "      <td id=\"T_33fa1_row5_col13\" class=\"data row5 col13\" >245</td>\n",
       "      <td id=\"T_33fa1_row5_col14\" class=\"data row5 col14\" >74</td>\n",
       "      <td id=\"T_33fa1_row5_col15\" class=\"data row5 col15\" >0</td>\n",
       "      <td id=\"T_33fa1_row5_col16\" class=\"data row5 col16\" >0</td>\n",
       "      <td id=\"T_33fa1_row5_col17\" class=\"data row5 col17\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_33fa1_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_33fa1_row6_col0\" class=\"data row6 col0\" >0</td>\n",
       "      <td id=\"T_33fa1_row6_col1\" class=\"data row6 col1\" >0</td>\n",
       "      <td id=\"T_33fa1_row6_col2\" class=\"data row6 col2\" >0</td>\n",
       "      <td id=\"T_33fa1_row6_col3\" class=\"data row6 col3\" >0</td>\n",
       "      <td id=\"T_33fa1_row6_col4\" class=\"data row6 col4\" >0</td>\n",
       "      <td id=\"T_33fa1_row6_col5\" class=\"data row6 col5\" >0</td>\n",
       "      <td id=\"T_33fa1_row6_col6\" class=\"data row6 col6\" >0</td>\n",
       "      <td id=\"T_33fa1_row6_col7\" class=\"data row6 col7\" >0</td>\n",
       "      <td id=\"T_33fa1_row6_col8\" class=\"data row6 col8\" >0</td>\n",
       "      <td id=\"T_33fa1_row6_col9\" class=\"data row6 col9\" >0</td>\n",
       "      <td id=\"T_33fa1_row6_col10\" class=\"data row6 col10\" >249</td>\n",
       "      <td id=\"T_33fa1_row6_col11\" class=\"data row6 col11\" >253</td>\n",
       "      <td id=\"T_33fa1_row6_col12\" class=\"data row6 col12\" >245</td>\n",
       "      <td id=\"T_33fa1_row6_col13\" class=\"data row6 col13\" >126</td>\n",
       "      <td id=\"T_33fa1_row6_col14\" class=\"data row6 col14\" >0</td>\n",
       "      <td id=\"T_33fa1_row6_col15\" class=\"data row6 col15\" >0</td>\n",
       "      <td id=\"T_33fa1_row6_col16\" class=\"data row6 col16\" >0</td>\n",
       "      <td id=\"T_33fa1_row6_col17\" class=\"data row6 col17\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_33fa1_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_33fa1_row7_col0\" class=\"data row7 col0\" >0</td>\n",
       "      <td id=\"T_33fa1_row7_col1\" class=\"data row7 col1\" >0</td>\n",
       "      <td id=\"T_33fa1_row7_col2\" class=\"data row7 col2\" >0</td>\n",
       "      <td id=\"T_33fa1_row7_col3\" class=\"data row7 col3\" >0</td>\n",
       "      <td id=\"T_33fa1_row7_col4\" class=\"data row7 col4\" >0</td>\n",
       "      <td id=\"T_33fa1_row7_col5\" class=\"data row7 col5\" >0</td>\n",
       "      <td id=\"T_33fa1_row7_col6\" class=\"data row7 col6\" >0</td>\n",
       "      <td id=\"T_33fa1_row7_col7\" class=\"data row7 col7\" >14</td>\n",
       "      <td id=\"T_33fa1_row7_col8\" class=\"data row7 col8\" >101</td>\n",
       "      <td id=\"T_33fa1_row7_col9\" class=\"data row7 col9\" >223</td>\n",
       "      <td id=\"T_33fa1_row7_col10\" class=\"data row7 col10\" >253</td>\n",
       "      <td id=\"T_33fa1_row7_col11\" class=\"data row7 col11\" >248</td>\n",
       "      <td id=\"T_33fa1_row7_col12\" class=\"data row7 col12\" >124</td>\n",
       "      <td id=\"T_33fa1_row7_col13\" class=\"data row7 col13\" >0</td>\n",
       "      <td id=\"T_33fa1_row7_col14\" class=\"data row7 col14\" >0</td>\n",
       "      <td id=\"T_33fa1_row7_col15\" class=\"data row7 col15\" >0</td>\n",
       "      <td id=\"T_33fa1_row7_col16\" class=\"data row7 col16\" >0</td>\n",
       "      <td id=\"T_33fa1_row7_col17\" class=\"data row7 col17\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_33fa1_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_33fa1_row8_col0\" class=\"data row8 col0\" >0</td>\n",
       "      <td id=\"T_33fa1_row8_col1\" class=\"data row8 col1\" >0</td>\n",
       "      <td id=\"T_33fa1_row8_col2\" class=\"data row8 col2\" >0</td>\n",
       "      <td id=\"T_33fa1_row8_col3\" class=\"data row8 col3\" >0</td>\n",
       "      <td id=\"T_33fa1_row8_col4\" class=\"data row8 col4\" >0</td>\n",
       "      <td id=\"T_33fa1_row8_col5\" class=\"data row8 col5\" >11</td>\n",
       "      <td id=\"T_33fa1_row8_col6\" class=\"data row8 col6\" >166</td>\n",
       "      <td id=\"T_33fa1_row8_col7\" class=\"data row8 col7\" >239</td>\n",
       "      <td id=\"T_33fa1_row8_col8\" class=\"data row8 col8\" >253</td>\n",
       "      <td id=\"T_33fa1_row8_col9\" class=\"data row8 col9\" >253</td>\n",
       "      <td id=\"T_33fa1_row8_col10\" class=\"data row8 col10\" >253</td>\n",
       "      <td id=\"T_33fa1_row8_col11\" class=\"data row8 col11\" >187</td>\n",
       "      <td id=\"T_33fa1_row8_col12\" class=\"data row8 col12\" >30</td>\n",
       "      <td id=\"T_33fa1_row8_col13\" class=\"data row8 col13\" >0</td>\n",
       "      <td id=\"T_33fa1_row8_col14\" class=\"data row8 col14\" >0</td>\n",
       "      <td id=\"T_33fa1_row8_col15\" class=\"data row8 col15\" >0</td>\n",
       "      <td id=\"T_33fa1_row8_col16\" class=\"data row8 col16\" >0</td>\n",
       "      <td id=\"T_33fa1_row8_col17\" class=\"data row8 col17\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_33fa1_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_33fa1_row9_col0\" class=\"data row9 col0\" >0</td>\n",
       "      <td id=\"T_33fa1_row9_col1\" class=\"data row9 col1\" >0</td>\n",
       "      <td id=\"T_33fa1_row9_col2\" class=\"data row9 col2\" >0</td>\n",
       "      <td id=\"T_33fa1_row9_col3\" class=\"data row9 col3\" >0</td>\n",
       "      <td id=\"T_33fa1_row9_col4\" class=\"data row9 col4\" >0</td>\n",
       "      <td id=\"T_33fa1_row9_col5\" class=\"data row9 col5\" >16</td>\n",
       "      <td id=\"T_33fa1_row9_col6\" class=\"data row9 col6\" >248</td>\n",
       "      <td id=\"T_33fa1_row9_col7\" class=\"data row9 col7\" >250</td>\n",
       "      <td id=\"T_33fa1_row9_col8\" class=\"data row9 col8\" >253</td>\n",
       "      <td id=\"T_33fa1_row9_col9\" class=\"data row9 col9\" >253</td>\n",
       "      <td id=\"T_33fa1_row9_col10\" class=\"data row9 col10\" >253</td>\n",
       "      <td id=\"T_33fa1_row9_col11\" class=\"data row9 col11\" >253</td>\n",
       "      <td id=\"T_33fa1_row9_col12\" class=\"data row9 col12\" >232</td>\n",
       "      <td id=\"T_33fa1_row9_col13\" class=\"data row9 col13\" >213</td>\n",
       "      <td id=\"T_33fa1_row9_col14\" class=\"data row9 col14\" >111</td>\n",
       "      <td id=\"T_33fa1_row9_col15\" class=\"data row9 col15\" >2</td>\n",
       "      <td id=\"T_33fa1_row9_col16\" class=\"data row9 col16\" >0</td>\n",
       "      <td id=\"T_33fa1_row9_col17\" class=\"data row9 col17\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_33fa1_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "      <td id=\"T_33fa1_row10_col0\" class=\"data row10 col0\" >0</td>\n",
       "      <td id=\"T_33fa1_row10_col1\" class=\"data row10 col1\" >0</td>\n",
       "      <td id=\"T_33fa1_row10_col2\" class=\"data row10 col2\" >0</td>\n",
       "      <td id=\"T_33fa1_row10_col3\" class=\"data row10 col3\" >0</td>\n",
       "      <td id=\"T_33fa1_row10_col4\" class=\"data row10 col4\" >0</td>\n",
       "      <td id=\"T_33fa1_row10_col5\" class=\"data row10 col5\" >0</td>\n",
       "      <td id=\"T_33fa1_row10_col6\" class=\"data row10 col6\" >0</td>\n",
       "      <td id=\"T_33fa1_row10_col7\" class=\"data row10 col7\" >43</td>\n",
       "      <td id=\"T_33fa1_row10_col8\" class=\"data row10 col8\" >98</td>\n",
       "      <td id=\"T_33fa1_row10_col9\" class=\"data row10 col9\" >98</td>\n",
       "      <td id=\"T_33fa1_row10_col10\" class=\"data row10 col10\" >208</td>\n",
       "      <td id=\"T_33fa1_row10_col11\" class=\"data row10 col11\" >253</td>\n",
       "      <td id=\"T_33fa1_row10_col12\" class=\"data row10 col12\" >253</td>\n",
       "      <td id=\"T_33fa1_row10_col13\" class=\"data row10 col13\" >253</td>\n",
       "      <td id=\"T_33fa1_row10_col14\" class=\"data row10 col14\" >253</td>\n",
       "      <td id=\"T_33fa1_row10_col15\" class=\"data row10 col15\" >187</td>\n",
       "      <td id=\"T_33fa1_row10_col16\" class=\"data row10 col16\" >22</td>\n",
       "      <td id=\"T_33fa1_row10_col17\" class=\"data row10 col17\" >0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f6507753940>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now let's color code the values\n",
    "df.style.set_properties(**{'font-size':'6pt'}).background_gradient('Greys')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## getting on with our baseline model\n",
    "\n",
    "The _baseline_ of our classifier will be very simple, as it should be:\n",
    "\n",
    "- find the average pixel value for every pixel of the 3s\n",
    "- find the average pixel value for every pixel of the 7s\n",
    "\n",
    "This gives us group averages that we may call \"ideal\" 3s and 7s. We would first classify a digit as a 3 if the average pixel value of the digit is closer to the ideal 3 than to the ideal 7, and vice versa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6131, 6265)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create lists of tensors containing all 3s and 7s stacked together\n",
    "mnist_seven_tensors = [tensor(Image.open(digit)) for digit in mnist_sevens]\n",
    "mnist_three_tensors = [tensor(Image.open(digit)) for digit in mnist_threes]\n",
    "len(mnist_three_tensors),len(mnist_seven_tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 100x100 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Jupyter ships with a function called `show_image` that knows how to render a tensor as an image\n",
    "show_image(mnist_three_tensors[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## rank-3 tensors\n",
    "\n",
    "For every pixel position, we want to compute the average over all the images of the intensity of that pixel. \n",
    "\n",
    "To do this we first combine all the images in this list into a single three-dimensional tensor. \n",
    "\n",
    "The most common way to describe such a tensor is to call it a _rank-3 tensor_.\n",
    "\n",
    "See an example of what that might look like below:\n",
    "\n",
    "![rank-3 tensor.png](./rank-3-tensor.png)\n",
    "\n",
    "### how did we conclude that we needed a rank-3 tensor?\n",
    "\n",
    "- Each image is a 2d matrix of pixels (rows and columns, e.g. a _rank-2 tensor_)\n",
    "- Each element in an image matrix corresponds to a pixel intensity (a scalar value, e.g. a _rank-1 tensor_)\n",
    "- To ease computing of the average of each pixel intensity over all images, you would stack each of these matrices on top of each other: there you have it, a _rank-3 tensor_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6131, 28, 28])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's stack our images and cast our stacked tensors as float tensors for further computation,\n",
    "# we also normalise our pixel values to be between 0 and 1 by dividing by 255\n",
    "stacked_mnist_sevens = torch.stack(mnist_seven_tensors).float()/255\n",
    "stacked_mnist_threes = torch.stack(mnist_three_tensors).float()/255\n",
    "\n",
    "# a _shape_ tells us the length of each axis of a tensor\n",
    "stacked_mnist_threes.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The previous output says to us: \"we have 6131 images, each of size 28x28 pixels\". \n",
    "\n",
    "We can define the _shape_ as **the size of each axis in a tensor**.\n",
    "\n",
    "As you may have noticed, we have also normalized the values of the pixels. We want all pixels to be between 0 and 1. By ensuring that all values are of similar scale, we improve the accuracy of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1026,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 1026,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the _length_ of a tensor's shape is its _rank_\n",
    "len(stacked_mnist_threes.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1027,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 1027,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# you could also get the rank of a tensor like so\n",
    "stacked_mnist_threes.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The _dimension_ 0 of our rank-3 tensor is the number of images.\n",
    "\n",
    "Here is how you would compute the average pixel intensity for each pixel position:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 100x100 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "baseline_3 = stacked_mnist_threes.mean(0)\n",
    "show_image(baseline_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 100x100 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# let's do the same thing for the 7s\n",
    "baseline_7 = stacked_mnist_sevens.mean(0)\n",
    "show_image(baseline_7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the baseline model\n",
    "\n",
    "Now that we have an idea of what our ideal 3 and 7 look like, we can try to classify our images. To test our baseline, we would pick an arbitrary number from the dataset and measure its distance from its _ideal_ representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 100x100 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# here is our sample number for our test\n",
    "ex3_2 = stacked_mnist_threes[1]\n",
    "show_image(ex3_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To calculate the distance from the baseline `3`, we can't just add up the differences in intensity between each of the pixels of both images. It is so because some differences would cancel out (light vs dark pixels), and that would be misleading as very different pixels could have a value of zero, which would mean \"no difference from the ideal digit representation\".\n",
    "\n",
    "There are two main ways data scientists measure distance in this context:\n",
    "\n",
    "- take the mean absolute value of differences: this is called _mean absolute difference_ or _L1 norm_\n",
    "- take the mean of the square of differences (which makes everything positive) and then take the square root (which undoes the squaring): this is called _root mean squared error_ or _L2 norm_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1114)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's try the `L1` norm\n",
    "ex3_2_dist_l1 = (ex3_2 - baseline_3).abs().mean()\n",
    "\n",
    "ex3_2_dist_l1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.2021)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's try the `L2` norm now\n",
    "ex3_2_dist_l2 = ((ex3_2 - baseline_3)**2).mean().sqrt()\n",
    "\n",
    "ex3_2_dist_l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.1586), tensor(0.1114))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's check if our arbitrary number is a 3 or a 7 using both methods,\n",
    "# the closer we are to 0, the more likely it is that our number is a 3\n",
    "\n",
    "# `L1` norm\n",
    "dist7_l1 = (ex3_2 - baseline_7).abs().mean()\n",
    "dist3_l1 = (ex3_2 - baseline_3).abs().mean()\n",
    "dist7_l1, dist3_l1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.3021), tensor(0.2021))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we'll use the `L2` norm\n",
    "dist7_l2 = ((ex3_2 - baseline_7)**2).mean().sqrt()\n",
    "dist3_l2 = ((ex3_2 - baseline_3)**2).mean().sqrt()\n",
    "dist7_l2, dist3_l2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the little experiment we've just run, we can see that our baseline model predicts right in this particular case, as both results are greater for a 7 than they would have been for a 3.\n",
    "\n",
    "We could have done the same thing with `PyTorch`, which provides loss functions (among many other things), as shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1586)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist7_l1_torch = F.l1_loss(ex3_2.float(), baseline_7)\n",
    "dist7_l1_torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.3021)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist7_l2_torch = F.mse_loss(ex3_2, baseline_7).sqrt()\n",
    "dist7_l2_torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining a metric for our baseline model\n",
    "\n",
    "A metric is a number that is calculated based on the predictions of our model, and the correct labels in our dataset, in order to tell us how good our model is.\n",
    "\n",
    "In practice, _accuracy_ is a common metric for classification models.\n",
    "\n",
    "- The _error rate_ in deep learning refers to the difference between the predicted output and the actual output of a neural network. It is a measure of how well the network is performing on a given task. In this context, _accuracy_ can be defined as `1.0 - error rate`.\n",
    "\n",
    "A metric is always calculated over a _validation_ set.\n",
    "\n",
    "To get a validation set, we need to set aside some of the data of the training set entirely, so it's not seen by the model at all during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1010, 28, 28]), torch.Size([1028, 28, 28]))"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's create tensors for 3s and 7s using the MNIST validation set\n",
    "mnist_validation_threes = torch.stack([tensor(Image.open(o)) for o in (path_to_mnist_sample/'valid'/'3').ls()])\n",
    "mnist_validation_threes = mnist_validation_threes.float()/255\n",
    "mnist_validation_sevens = torch.stack([tensor(Image.open(o)) for o in (path_to_mnist_sample/'valid'/'7').ls()])\n",
    "mnist_validation_sevens = mnist_validation_sevens.float()/255\n",
    "\n",
    "# here we divided both tensors by 255 to normalize the pixel values between 0 and 1\n",
    "# x images of size 28x28 pixels\n",
    "mnist_validation_threes.shape,mnist_validation_sevens.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our case we have more sevens in our validation set than threes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1114)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now let's write the function that will give use the Mean Absolute Difference loss for a given image\n",
    "def mnist_mad_distance(a,b): return (a-b).abs().mean((-1,-2))\n",
    "mnist_mad_distance(ex3_2, baseline_3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### why `mean((-1,-2))`\n",
    "\n",
    "The `mean` function in `PyTorch` can take a tuple of axes to take the mean of. \n",
    "In this case, we want to take the mean over the last two dimensions (in this case, the horizontal and vertical dimensions of an image).\n",
    "\n",
    "The tuple `(-1,-2)` represents a range of axes.\n",
    "\n",
    "This effectively allows us to make batch calculations on rank-3 tensors, as you will see in the example below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.1463, 0.1526, 0.1214,  ..., 0.1360, 0.1326, 0.1422]),\n",
       " torch.Size([1010, 28, 28]),\n",
       " torch.Size([28, 28]),\n",
       " torch.Size([1010]))"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# applying the same calculation for every image in our validation set\n",
    "valid_3_dist = mnist_mad_distance(mnist_validation_threes, baseline_3)\n",
    "valid_3_dist, mnist_validation_threes.shape, baseline_3.shape, valid_3_dist.shape\n",
    "\n",
    "# for every image, we averaged the intensity of all pixels in that image;\n",
    "# we are left with a rank-1 tensor of a thousand numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`PyTorch` is so versatile it didn't even complain about shapes not matching and calculated the distance for each image instead !\n",
    "\n",
    "This is made possible because `PyTorch` uses _broadcasting_ under the hood: e.g. the ability expand a lower rank tensor to have the same size as a higher rank input tensor during a calculation. This is why this type of operation is possible:\n",
    "\n",
    "```python\n",
    "tensor([1,2,3]) + tensor(1) # tensor([2,3,4])\n",
    "```\n",
    "\n",
    "Now let's continue with the function that determines if the number is a `3` or a `7`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1040,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(True), tensor(1.))"
      ]
     },
     "execution_count": 1040,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def is_3(x): return mnist_mad_distance(x,baseline_3) < mnist_mad_distance(x,baseline_7)\n",
    "\n",
    "# let's test the function\n",
    "is_3(ex3_2), is_3(ex3_2).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1041,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([True, True, True,  ..., True, True, True])"
      ]
     },
     "execution_count": 1041,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's do the same thing at scale\n",
    "is_3(mnist_validation_threes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1042,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1.,  ..., 1., 1., 1.])"
      ]
     },
     "execution_count": 1042,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# again but as floats\n",
    "is_3(mnist_validation_threes).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1043,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9168)"
      ]
     },
     "execution_count": 1043,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the mean of correct predictions\n",
    "accuracy_3s = is_3(mnist_validation_threes).float().mean()\n",
    "accuracy_3s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1044,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9854)"
      ]
     },
     "execution_count": 1044,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's do the above steps for 7s\n",
    "accuracy_7s = (1 - is_3(mnist_validation_sevens).float()).mean()\n",
    "accuracy_7s\n",
    "\n",
    "# we use the inverse here with `1 - is_3` because we want to know how many 7s we correctly identified (OR logic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can conclude from the above that we have a pretty good baseline for 2 numbers !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using another approach to classify digits: a linear model with SGD\n",
    "\n",
    "In our pixels similarity approach, we don't have any kind of weight assignment, or any way of improving our classifier based on testing the effectiveness of a weight assignment.\n",
    "\n",
    "_Stochastic gradient descent_ is a technique used to update the weights of a neural network in order to make it improve at any given task. Its power resides in the fact that it provides a way of finding weight values automatically.\n",
    "\n",
    "Now, back to our problem.\n",
    "\n",
    "Instead of trying to find the similarity between an image and an \"ideal image,\" we could instead look at each individual pixel and come up with a set of weights for each one.\n",
    "\n",
    "For instance, pixels toward the bottom right are not very likely to activate neurons for a 7, so they should have a low weight for a 7, but they are likely to be activated for an 8, so they should have a high weight for an 8. \n",
    "\n",
    "This can be represented as a function with a set of weight values for each possible category, for instance the probability of being the number 8 =>\n",
    "\n",
    "```python\n",
    "def pr_eight(image_vector, weights_vector): return (image_vector * weights_vector).sum()\n",
    "```\n",
    "\n",
    "Here, the image represented as a vector is basically \"all the rows stacked up end to end on a single long line\". With this kind of function, we just need some way to update the weights to make them better and better at distinguishing between digits: we want to find the specific values for the weights that cause the result of our function to be high for images that are actually 8s, and low for images that are not. Searching for the best weights is a way of searching for the best function that recognizes 8s.\n",
    "\n",
    "These are the steps that will turn our function into a machine learning classifier:\n",
    "\n",
    "1. _Initialize_ the weights with random values\n",
    "2. For each image, use these weights to predict whether it appears to be a 3 or a 7\n",
    "3. Based on these predictions, calculate how good the model is (its _loss_)\n",
    "4. Calculate the _gradient_, which measures for each weight, how changing that weight would change the loss; the gradients will tell us how much we have to change each weight to make our model better\n",
    "5. _Step_ (that is, _change_) all the weights based on the previous calculation\n",
    "6. Go back to step 2 and repeat the process\n",
    "7. Iterate until you decide to stop the training process (for instance, because the model is good enough or you don't want to wait any longer). Generally, you would want to stop the training process when the model stops improving or gets worse\n",
    "\n",
    "These relatively simple steps are the basis for nearly all deep learning models.\n",
    "\n",
    "When we know how a function changes, we know what we need to make its value smaller. This is what weights assignment is all about.\n",
    "\n",
    "One important thing to be aware of is that our function has lots of weights that we need to adjust, so when we calculate the derivative of these weights we won't get back one number, but rather lots of them: a _gradient_ for every weight. But there is nothing mathematically tricky here; you can calculate the derivative with respect to one weight, and treat all the other ones as constant, then repeat that for each other weight. This is how all of the gradients are calculated, for every weight.\n",
    "\n",
    "Thankfully, `PyTorch` can automatically compute the derivative of nearly any function!\n",
    "Adjusting the weights of our model can be then expressed as simply as:\n",
    "\n",
    "```python\t\n",
    "weights -= gradient * lr\n",
    "```\n",
    "\n",
    "This is what _stepping the weights_ actually means.\n",
    "\n",
    "We use a substraction here to allow for:\n",
    "\n",
    "- in case the slope is positive, the weight to be decreased\n",
    "- in case the slope is negative, the weight to be increased\n",
    "\n",
    "Remember: our ultimate goal is to minimize the loss.\n",
    "\n",
    "Let's summarize a few points here:\n",
    "\n",
    "- The weights of a model can be random (training a model from scratch) or they can come from a pre trained model (transfer learning).\n",
    "- If you train a model from scratch, the first outputs you'll get will probably be pretty bad, because your weights are random.\n",
    "- Also, in case of a pretrained model, the first outputs won't probably be what you want, because the model was trained for a different task. So, the model will need to _learn_ better weights.\n",
    "- To measure the performance of a model, you compare the outputs the model gives you with the targets (the true labels), using a loss function.\n",
    "- We want the output of the loss function to be as low as possible by improving the weights of the model.\n",
    "- For improving the model, you'd want to set aside a few data items that you don't train the model on, called the _validation set_. This is the set that will be used to measure performance.\n",
    "- Figuring out how to change the loss to make it better heavily relies on Calculus and gradients. This is made easy with tools like `PyTorch` 😎.\n",
    "- At each pass of the iterative process that makes the weights better, we use the magnitude of each gradient to tell us how big a step is to take into a better direction. We multiply the gradients by a number called the _learning rate_ to decide each step size.\n",
    "- When the loss does not get any better, we say that the model has _converged_ and we stop the training.\n",
    "\n",
    "Alright, we are ready to apply this to the MNIST dataset now !\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining training and validation sets + parameters\n",
    "\n",
    "For our digits classifier issue to solve, we already have independent variables (x-axis): these are the images themselves. This means we can put together our training dataset.\n",
    "\n",
    "Let's concatenate all of them into a single tensor.\n",
    "\n",
    "To do this, we'll need to go from a rank-3 tensor of images stacked together to a list of vectors (rank-2 tensor). This can be done using the `view` method of `PyTorch` tensors, as it changes the shape of a tensor without changing its contents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# `torch.cat` concatenates tensors along the first dimension;\n",
    "# then `view` reshapes the concatenated tensor into a rank-2 tensor,\n",
    "# this new tensor has 28*28 columns and a number of rows equal to the number of images in the 2 original tensors;\n",
    "# a 28*28 image is flattened into a 784 pixels vector\n",
    "train_x = torch.cat([stacked_mnist_threes, stacked_mnist_sevens]).view(-1, 28*28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's label each image\n",
    "train_y = tensor([1]*len(mnist_threes) + [0]*len(mnist_sevens)).unsqueeze(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The line of code above:\n",
    "\n",
    "- concatenates 2 tensors of length `len(threes)` and `len(sevens)` respectively\n",
    "- the first elements of this new tensor (`len(threes)`) are set to 0\n",
    "- the last elements of this new tensor (`len(sevens)`) are set to 1\n",
    "- calling `unsqueeze` on a tensor adds an extra dimension to it\n",
    "- we add one extra dimension to match the shape of the images tensor that will be fed to the model\n",
    "- the resulting tensor has a shape of `(n, 1)`, where `n` is the number of images in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([12396, 784]), torch.Size([12396, 1]))"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape,train_y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A `Dataset` in `PyTorch` is an abstract class that represents a collection of data samples.\n",
    "\n",
    "When indexed, a `Dataset` is required to return a tuple of `(x,y)`, where `x` is the input data and `y` is the label.\n",
    "\n",
    "Let's create our `Dataset` of images and labels using the `zip` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([784]), tensor([1]))"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set = list(zip(train_x,train_y))\n",
    "\n",
    "# taking a look at the first element of the dataset,\n",
    "# here, `y` represents the label of the image\n",
    "x,y = training_set[0] \n",
    "x.shape,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now, let's put together our validation set\n",
    "valid_x = torch.cat([mnist_validation_threes, mnist_validation_sevens]).view(-1, 28*28)\n",
    "valid_y = tensor([1]*len(mnist_validation_threes) + [0]*len(mnist_validation_sevens)).unsqueeze(1)\n",
    "validation_set = list(zip(valid_x,valid_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.9269],\n",
       "        [ 1.4873],\n",
       "        [ 0.9007],\n",
       "        [-2.1055],\n",
       "        [ 0.6784]], grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's initialize our weights for every pixel with random values\n",
    "\n",
    "# this function returns a tensor of size `size` filled with random values from a normal distribution with a standard deviation of `std`\n",
    "def init_params(size, std=1.0): return (torch.randn(size)*std).requires_grad_()\n",
    "\n",
    "weights = init_params((28*28,1))\n",
    "# print a sample of our weights\n",
    "weights[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the goal is to multiply each pixel of the images by a weight value, we should take into account the fact that some pixels will have a value of `0`.\n",
    "\n",
    "This means that the function `weights * pixels` won't be flexible enough for our purpose since it can sometimes result in a value of `0` even if the weight is not `0`. That's not we want.\n",
    "\n",
    "Now, since the equation of a straight line is `y = wx + b`, we can add a constant `b` to our function to make it more flexible. This is called a _bias_.\n",
    "\n",
    "Together, the _weights_ and the _bias_ are called the _parameters_ of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.3472], requires_grad=True)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bias = init_params(1)\n",
    "bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1051,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([8.3031], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 1051,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we are now able to calculate a prediction for an image,\n",
    "# this is a simple implementation of a linear regression model;\n",
    "# `weights.T` means \"taking the transpose of the weights tensor\",\n",
    "# this is done because we want to multiply the weights by the pixels of the image,\n",
    "# so we turn the `weights` matrix rows into columns and vice versa\n",
    "(train_x[0]*weights.T).sum() + bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While we could use a Python for loop to calculate the prediction for each image, that would be very slow. Because Python loops don't run on the GPU, and because Python is a slow language for loops in general, we need to represent as much of the computation in a model as possible using higher-level functions.\n",
    "\n",
    "In this case, there's an extremely convenient mathematical operation that calculates `w*x` for every row of a matrix: matrix multiplication.\n",
    "\n",
    "In Python, matrix multiplication is represented with the `@` operator. Let's try it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1052,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([784, 1])"
      ]
     },
     "execution_count": 1052,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1053,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12396, 784])"
      ]
     },
     "execution_count": 1053,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ -6.2330],\n",
       "        [-10.6388],\n",
       "        [-20.8865],\n",
       "        ...,\n",
       "        [-15.9176],\n",
       "        [ -1.6866],\n",
       "        [-11.3568]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def multiply_data_by_params_model(independent_variables): return independent_variables@weights + bias\n",
    "preds = multiply_data_by_params_model(train_x)\n",
    "preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The equation `batch @ weights + bias` is a fundamental equation of any neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## checking our model's accuracy\n",
    "\n",
    "Let's check our accuracy. To decide if an output represents a 3 or a 7, we can just check whether it's greater than 0.0, since a 3 is a one and a 7 is a 0, so our accuracy for each item can be calculated (using broadcasting and no loops!) with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False],\n",
       "        [False],\n",
       "        [False],\n",
       "        ...,\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "corrects = (preds > 0.0).float() == train_y\n",
    "corrects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5379961133003235"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# our accuracy would be ...\n",
    "corrects.float().mean().item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choosing a loss function\n",
    "\n",
    "As we've seen, we need gradients in order to improve our model using SGD, and in order to calculate gradients we need some loss function that represents how good our model is. That is because the gradients are a measure of how the loss function changes with small tweaks to the weights. So, we need to choose a loss function.\n",
    "\n",
    "A very small change of a weight won't influence the overall accuracy of the model, so we can exclude accuracy as our loss function.\n",
    "\n",
    "Instead, we need a loss function which, when our weights result in slightly better predictions, gives us a slightly better loss. So what does a \"slightly better prediction\" look like, exactly? Well, in this case, it means that if the correct answer is a 3 the score is a little higher, or if the correct answer is a 7 the score is a little lower.\n",
    "\n",
    "The loss function receives not the images themselves, but the predictions from the model. Let's make one argument, `predictions`, of values between 0 and 1, where each value is the prediction that an image is a 3. It is a vector (i.e., a rank-1 tensor), indexed over the images.\n",
    "\n",
    "The purpose of the loss function is to measure the difference between predicted values and the true values — that is, the targets (aka labels). Let's make another parameter, `targets`, with values of 0 or 1 which tells whether an image actually is a 3 or not. It is also a vector (i.e., another rank-1 tensor), indexed over the images.\n",
    "\n",
    "Let's try this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# measure how distant each prediction is from 1 if it should be 1, \n",
    "# and how distant it is from 0 if it should be 0, \n",
    "# and then take the mean of all those distances\n",
    "\n",
    "def mnist_loss(predictions, targets):\n",
    "    # The 'torch.where' function takes three arguments: condition, x, and y.\n",
    "    # It returns a new tensor where each element comes from either 'x' or 'y', depending on the corresponding element in 'condition'.\n",
    "    return torch.where(\n",
    "        targets == 1,  # Condition: Check where the targets are 1\n",
    "        1 - predictions,  # x: If target is 1, loss is (1 - prediction)\n",
    "        predictions  # y: If target is 0, loss is (prediction)\n",
    "    ).mean()  # Calculate the mean of the resulting tensor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`torch.where(condition, x, y)` is a PyTorch function that takes a condition and two tensors x and y. For each element in the condition tensor, it will choose the corresponding element from x if the condition is True, and from y if the condition is False.\n",
    "\n",
    "The function above will return a lower number when:\n",
    "\n",
    "- predictions are more accurate\n",
    "- accurate predictions are more confident\n",
    "- inaccurate predictions are less confident\n",
    "\n",
    "One problem with `mnist_loss` as currently defined is that it assumes that predictions are always between 0 and 1. We need to ensure, then, that this is actually the case! As it happens, there is a function that does exactly that: the _sigmoid_ function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's update the `mnist_loss` function to use the sigmoid function\n",
    "def mnist_loss(predictions, targets):\n",
    "    predictions = predictions.sigmoid()\n",
    "    return torch.where(targets==1, 1-predictions, predictions).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Putting our linear modal together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([256, 784]), torch.Size([256, 1]))"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initialize our parameters\n",
    "weights = init_params((28*28,1))\n",
    "bias = init_params(1)\n",
    "\n",
    "# creating a data loader that will return batches of a given size shuffled for every epoch\n",
    "training_data_loader = DataLoader(training_set, batch_size=256)\n",
    "x,y = first(training_data_loader)\n",
    "x.shape,y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a data loader for the validation set\n",
    "validation_data_loader = DataLoader(validation_set, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's define a few functions that will help us calculate the gradients and update the weights and biases\n",
    "\n",
    "# let's also write a function that calculates accuracy for each batch\n",
    "def batch_accuracy(independent_variables, dependent_variables):\n",
    "    preds = independent_variables.sigmoid()\n",
    "    correct = (preds > 0.5) == dependent_variables\n",
    "    return correct.float().mean()\n",
    "\n",
    "# let's put this logic into a function for:\n",
    "#  - making predictions\n",
    "#  - calculating the loss\n",
    "#  - calculating the gradients\n",
    "def calc_grad(independent_variables, dependent_variables, model):\n",
    "    preds = model(independent_variables)\n",
    "    loss = mnist_loss(preds, dependent_variables)\n",
    "    # The `backward` function actually adds the gradients of `loss` to any gradients that are currently stored.\n",
    "    loss.backward()\n",
    "\n",
    "# we need to update the weights and biases based on the gradient and learning rate\n",
    "def train_epoch(model, lr, params):\n",
    "    for x, y in training_data_loader:\n",
    "        calc_grad(x, y, model)\n",
    "        for p in params:\n",
    "            p.data -= p.grad*lr\n",
    "            # we have to tell `PyTorch` to not store the gradients for this step,\n",
    "            # otherwise they would accumulate and things could get very confusing\n",
    "            p.grad.zero_()\n",
    "\n",
    "# let's write a validation function,\n",
    "# this function `validate_epoch` takes a PyTorch model as input and evaluates its accuracy on a validation dataset.\n",
    "# It does so by iterating over batches of data in the validation dataloader, \n",
    "# passing each batch through the model to get the predicted outputs, \n",
    "# and comparing those predictions to the true labels (`dependent_variables`) to calculate the accuracy of each batch. \n",
    "# The function then returns the average accuracy across all batches, rounded to 4 decimal places.\n",
    "def validate_epoch(model):\n",
    "    accs = [batch_accuracy(model(independent_variables), dependent_variables) for independent_variables, dependent_variables in validation_data_loader]\n",
    "    return round(torch.stack(accs).mean().item(), 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6546"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's run a first iteration of our model\n",
    "lr = 1.\n",
    "params = weights, bias\n",
    "train_epoch(multiply_data_by_params_model, lr, params)\n",
    "validate_epoch(multiply_data_by_params_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8158 0.8915 0.9291 0.9413 0.9486 0.953 0.956 0.9574 0.9589 0.9599 "
     ]
    }
   ],
   "source": [
    "# then let's do a few more rounds\n",
    "for i in range(10):\n",
    "    train_epoch(multiply_data_by_params_model, lr, params)\n",
    "    print(validate_epoch(multiply_data_by_params_model), end=' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... this is pretty promising !\n",
    "\n",
    "Now let's create an object that will handle the SGD steps for us. In `PyTorch`, it's called an _optimizer_.\n",
    "\n",
    "There is a module in `PyTorch` called `nn.Linear`: it does the same things as `init_params` and `multiply_data_by_params_model` together.\n",
    "\n",
    "It will contain both the weights and the biases of our model in a single class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 784]), torch.Size([1]))"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_model = nn.Linear(28*28,1)\n",
    "\n",
    "weights, biases = linear_model.parameters()\n",
    "weights.shape, biases.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's use that to create our basic optimizer\n",
    "class BasicOptim:\n",
    "    def __init__(self,params,lr): self.params,self.lr = list(params),lr\n",
    "\n",
    "    def step(self, *args, **kwargs):\n",
    "        for p in self.params: p.data -= p.grad.data * self.lr\n",
    "\n",
    "    def zero_grad(self, *args, **kwargs):\n",
    "        for p in self.params: p.grad = None\n",
    "\n",
    "# let's make an instance of it using our model's parameters\n",
    "opt = BasicOptim(linear_model.parameters(), lr)   \n",
    "\n",
    "# this simplifies our training loop to:\n",
    "def train_epoch(model):\n",
    "    for x, y in training_data_loader:\n",
    "        calc_grad(x, y, model)\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "\n",
    "# we can now write a function that trains our model:\n",
    "def train_model(model, epochs):\n",
    "    for i in range(epochs):\n",
    "        train_epoch(model)\n",
    "        print(validate_epoch(model), end=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4932 0.8262 0.8408 0.9126 0.9341 0.9468 0.9555 0.9629 0.9653 0.9668 0.9692 0.9717 0.9731 0.9751 0.9761 0.9765 0.9775 0.9785 0.9785 0.9785 "
     ]
    }
   ],
   "source": [
    "# let's try it out\n",
    "train_model(linear_model, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we have just did with `BasicOptim` is implemented in `fastai` with the `SGD` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4932 0.749 0.8579 0.917 0.9365 0.9521 0.957 0.9629 0.9658 0.9687 0.9707 0.9721 0.9731 0.9746 0.9761 0.9765 0.9775 0.978 0.978 0.978 "
     ]
    }
   ],
   "source": [
    "linear_model = nn.Linear(28*28,1)\n",
    "opt = SGD(linear_model.parameters(), lr)\n",
    "train_model(linear_model, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, the implementation of our `train_model` function in `fastai` is called `Learner.fit`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = DataLoaders(training_data_loader, validation_data_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are about to create a `Learner` without using an application such as `vision_learner`. For this, we can pass in all the elements that we've created: \n",
    "\n",
    "- any metrics we want to use (accuracy in this case)\n",
    "- the data loaders\n",
    "- the loss function\n",
    "- the model\n",
    "- the optimization function, which will be passed the parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>batch_accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.636516</td>\n",
       "      <td>0.503599</td>\n",
       "      <td>0.495584</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.567307</td>\n",
       "      <td>0.194196</td>\n",
       "      <td>0.835623</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.207229</td>\n",
       "      <td>0.181414</td>\n",
       "      <td>0.835132</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.089765</td>\n",
       "      <td>0.106924</td>\n",
       "      <td>0.910206</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.046562</td>\n",
       "      <td>0.078032</td>\n",
       "      <td>0.932777</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.029760</td>\n",
       "      <td>0.062546</td>\n",
       "      <td>0.947007</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.022909</td>\n",
       "      <td>0.052922</td>\n",
       "      <td>0.955839</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.019906</td>\n",
       "      <td>0.046520</td>\n",
       "      <td>0.961236</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.018408</td>\n",
       "      <td>0.042010</td>\n",
       "      <td>0.965162</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.017523</td>\n",
       "      <td>0.038679</td>\n",
       "      <td>0.967125</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learner = Learner(dls, nn.Linear(28*28,1), opt_func=SGD, loss_func=mnist_loss, metrics=batch_accuracy)\n",
    "\n",
    "# now we can call `fit` to train our model across multiple epochs\n",
    "learner.fit(10, lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing our own neural network\n",
    "\n",
    "Let's try to write a very basic neural network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# an illustration of the universal approximation theorem\n",
    "def simple_net(independent_variables): \n",
    "    res = independent_variables@w1 + b1\n",
    "    # here we have our relu activation function\n",
    "    res = res.max(tensor(0.0))\n",
    "    res = res@w2 + b2\n",
    "    return res\n",
    "\n",
    "# let's use this\n",
    "# here `w1` is the weights matrix connecting the input layer to a layer of 30 neurons (the hidden layer)\n",
    "w1 = init_params((28*28,30))\n",
    "b1 = init_params(30)\n",
    "# here `w2` is the weights matrix connecting the hidden layer to the output layer, which has a single neuron (since we're just trying to predict one number, 3 or 7)\n",
    "w2 = init_params((30,1))\n",
    "b2 = init_params(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above example, the first hidden layer can construct 30 different features, each representing some different mix of pixels. Changing the value `30` will result in a more or less complex model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>batch_accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.334446</td>\n",
       "      <td>0.408529</td>\n",
       "      <td>0.505397</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.154280</td>\n",
       "      <td>0.237300</td>\n",
       "      <td>0.792444</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.084378</td>\n",
       "      <td>0.118382</td>\n",
       "      <td>0.910697</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.054719</td>\n",
       "      <td>0.079430</td>\n",
       "      <td>0.939647</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.041056</td>\n",
       "      <td>0.061905</td>\n",
       "      <td>0.956330</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.034140</td>\n",
       "      <td>0.052130</td>\n",
       "      <td>0.963199</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.030212</td>\n",
       "      <td>0.045985</td>\n",
       "      <td>0.964181</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.027690</td>\n",
       "      <td>0.041786</td>\n",
       "      <td>0.966143</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.025886</td>\n",
       "      <td>0.038731</td>\n",
       "      <td>0.968106</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.024494</td>\n",
       "      <td>0.036397</td>\n",
       "      <td>0.969087</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.023369</td>\n",
       "      <td>0.034541</td>\n",
       "      <td>0.972522</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.022430</td>\n",
       "      <td>0.033021</td>\n",
       "      <td>0.972522</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.021631</td>\n",
       "      <td>0.031744</td>\n",
       "      <td>0.973013</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.020940</td>\n",
       "      <td>0.030651</td>\n",
       "      <td>0.973994</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.020336</td>\n",
       "      <td>0.029700</td>\n",
       "      <td>0.974975</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.019802</td>\n",
       "      <td>0.028860</td>\n",
       "      <td>0.976448</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.019324</td>\n",
       "      <td>0.028115</td>\n",
       "      <td>0.976938</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.018894</td>\n",
       "      <td>0.027446</td>\n",
       "      <td>0.977920</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.018504</td>\n",
       "      <td>0.026845</td>\n",
       "      <td>0.978410</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.018149</td>\n",
       "      <td>0.026299</td>\n",
       "      <td>0.978901</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.017822</td>\n",
       "      <td>0.025802</td>\n",
       "      <td>0.978901</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.017520</td>\n",
       "      <td>0.025347</td>\n",
       "      <td>0.978901</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.017240</td>\n",
       "      <td>0.024929</td>\n",
       "      <td>0.979882</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.016979</td>\n",
       "      <td>0.024544</td>\n",
       "      <td>0.979882</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.016734</td>\n",
       "      <td>0.024187</td>\n",
       "      <td>0.980373</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.016504</td>\n",
       "      <td>0.023857</td>\n",
       "      <td>0.979882</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.016288</td>\n",
       "      <td>0.023551</td>\n",
       "      <td>0.980373</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.016083</td>\n",
       "      <td>0.023266</td>\n",
       "      <td>0.980373</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.015890</td>\n",
       "      <td>0.022999</td>\n",
       "      <td>0.980864</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.015706</td>\n",
       "      <td>0.022751</td>\n",
       "      <td>0.981845</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.015531</td>\n",
       "      <td>0.022518</td>\n",
       "      <td>0.981845</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>0.015365</td>\n",
       "      <td>0.022300</td>\n",
       "      <td>0.981845</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.015206</td>\n",
       "      <td>0.022095</td>\n",
       "      <td>0.982336</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>0.015054</td>\n",
       "      <td>0.021903</td>\n",
       "      <td>0.982336</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>0.014908</td>\n",
       "      <td>0.021721</td>\n",
       "      <td>0.982336</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>0.014769</td>\n",
       "      <td>0.021549</td>\n",
       "      <td>0.982336</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>0.014634</td>\n",
       "      <td>0.021387</td>\n",
       "      <td>0.982336</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>0.014505</td>\n",
       "      <td>0.021233</td>\n",
       "      <td>0.982826</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>0.014381</td>\n",
       "      <td>0.021087</td>\n",
       "      <td>0.982336</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>0.014261</td>\n",
       "      <td>0.020948</td>\n",
       "      <td>0.982336</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# `PyTorch` version of our simple neural network\n",
    "simple_net = nn.Sequential(\n",
    "    nn.Linear(28*28,30),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(30,1)\n",
    ")\n",
    "\n",
    "learn = Learner(dls, simple_net, opt_func=SGD,\n",
    "    loss_func=mnist_loss, metrics=batch_accuracy)\n",
    "\n",
    "learn.fit(40, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f6541587bb0>]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAigAAAGjCAYAAAAGku4DAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA1AUlEQVR4nO3de3hU9YH/8c9kkswMuRIDkkiCF8AbxuiWRPm51FaXVSztVgJUoREfuvjrY/HSZWHzU+qlKt1Fqfq4ulIpAlKpxrJVvC0qsio3reB6Y2PVhECi3JJMAplJZnJ+f4QZciVzhpk5M+H9ep55knxnTuZ78kXPZ763YzMMwxAAAEAcSbK6AgAAAD0RUAAAQNwhoAAAgLhDQAEAAHGHgAIAAOIOAQUAAMQdAgoAAIg7BBQAABB3CCgAACDuEFAAAEDcSTZ7QEtLi5YsWaJt27Zp+/btamho0IoVKzR79uyQjm9sbNSCBQu0bt06HTlyRCUlJXrooYd08cUXh1yHjo4O1dXVKSMjQzabzewpAAAACxiGoebmZuXn5yspaYA+EsOkr7/+2pBkFBYWGpdffrkhyVixYkVIx/r9fmPChAlGWlqacffddxuPPfaYcd555xkZGRlGVVVVyHWora01JPHgwYMHDx48EvBRW1s74LXedA9KXl6e6uvrNWLECH3wwQcaP358yMdWVlZq8+bNev7551VWViZJmj59usaOHau77rpLf/jDH0L6PRkZGZKk2tpaZWZmmj0FAABgAbfbrYKCguB1/HhMBxSHw6ERI0aEVbHKykqdeuqpuvbaa4Nlw4YN0/Tp0/XMM8/I6/XK4XAM+HsCwzqZmZkEFAAAEkwo0zNiOkl2x44duvjii3uNO5WUlOjIkSOqqqrq8ziv1yu3293tAQAABq+YBpT6+nrl5eX1Kg+U1dXV9Xnc4sWLlZWVFXwUFBREtZ4AAMBaMQ0ora2tfQ7hOJ3O4PN9qaioUFNTU/BRW1sb1XoCAABrmZ6DciJcLpe8Xm+vco/HE3y+Lw6HI6S5KQAAYHCIaQ9KYAVQT4Gy/Pz8WFYHAADEqZgGlOLiYn344Yfq6OjoVr5t2zYNGTJEY8eOjWV1AABAnIpaQKmvr9euXbvU3t4eLCsrK9O3336rP/3pT8GyAwcO6Pnnn9eUKVMYxgEAAJLCnIPy2GOPqbGxMbjq5qWXXtKePXskSfPmzVNWVpYqKiq0cuVKff311zr99NMldQaUSy65RDfeeKM+++wz5ebm6vHHH5ff79c999wTmTMCAAAJL6yA8uCDD6qmpib485/+9Kdgr8isWbOUlZXV53F2u12vvPKK/vmf/1mPPvqoWltbNX78eD399NM6++yzw6kKAAAYhGyGYRhWV8Ist9utrKwsNTU1sZMsAAAJwsz1O6aTZAEAAEJBQAEAAHEnphu1AQAQCf4OQ22+Dnl9/qNfO7/3+jrU5utQws1dkGQYks/foTZ/h7ztR7/6/Me+D37tPM92v6GUZJscyXY5kpOCj9TkpGBZ4PvU5CTZk2wK4R59QblpDhWeMiR6JzwAAgoAnOS6Xuy9vsCF0K/Wtg41e9rl9vi6fW32+ORu7fza7D32c7s/erHA32F0CyO+jkSMIInl+tJCPfDjCyx7fwIKgEHPMAwdbvMHL67Nnna5W31yBy62nna1+0K/4BkyghfK3p/ie5d1GEbwU2zPT7nHyjq/T01Okr+jo/en5h6fpL1HP0mbuVAbhiFfh9F5/CC62CfZ1NljkNL5t0yxJynJTFdBHEm223r9W3H0+rfS+e8k2Z6kdl+XfxM+f5fvO7qHTl+H/CbbOWdIapTOMjQEFAB98vk71Ozx6XCbr8un6mPdyz3/Bxj8PnhB7V7m7aOL2tdjV+lI8ncoGEhavD7T/3M+WSXZJGfKsYthpjNFGc5kZRz9muk6+tXZ/WuGM0WpydGb1mi32YIBpOfFOtnOdMrBiIACJDhPu1/NHl+PoNBXYOj8xOxp71CLt0vvQWuXXoUuXfhH2vxWn1rEJSfZul1kMxwpynR1XlwdJi+uvcf5j108HSlJSrUnHb2g2mWTggGtv96WrkMryUldfl+Kvcvv6j2/IDkpydS8ghR7P5/Kj9aZiz3iBQEFiDOGYehIm18HWrw60OLV/uY2HWjx6mBLW7Cs89GmA81eNXt9Ua1PanKSnL0ulD0vzMd+dgYvzkfL7EldLtjdJ+4l222KVkd8ks2mdGeyMoOf8lPkTEmSLUG7/oGTDQEFiDCvzy93a5fJhD3mPRzrqQg8F3i+8+cWjy+sOQE9P133ChBdPtWnO7p02Xfpos90de+6T3cmK4VP1AAsQEDBoOTzd+iv+1tUc/BIyMcYhuTr6D1PIjhk0qOs9ejQStcg4vb41OaLzLwKZ0qSctMdwcewjNRuP+empyo3o/P7TGcyPQMABhUCChKeYRiqPdSqj/Y06qPaRv3PniZ9vLdJre3WzqHIcCR3m1zYe4Jh9/LMQC/G0fIhqXZCB4CTFgEFCWd/s1f/s6dRH+1pOhpIGtVwpL3X69IdyTpreLqSk0K/yCcn2XrMk+h/iZ8j2d45wdLRfYgkw5midEey7CbeFwDQHQEFlvH6/PqmyaP9zd5uQyS9NoLqMoTScKRd+5u9vX5Xqj1J5+Zn6sKRWbpwZLYuLMjSmbnpSiIkAEBCIqAgKgzDkNvj096GVtU1tmpv18fRsv0tXoVzL22bTRo9LF1FI7NVXJClopHZOicvQ45ke+RPBABgCQIKwuLvMLSv2aO6xlbtaWhVXaNHexuPHA0fHu1tbFVLCMtfnSlJGp7hVJbr2HyMrvMwAvM1AkMnGc5knZGbpgxnSgzOEgBgFQIKJEkdHYZa2ny9lsMGft7X7D3W+9HUqvpGT0hLYXPSUnVatkv52U6dlj1E+dlOjRzqCn6fk5bKRFAAQC8ElJNM05F2Pf+XWr3x+bdqPHJsbkeL12d6uCU5yaYRWU7lZ7s0Mtul/GyXTht69OvRUDIklX9iAADzuHqcJD7Z26TVW2r054/2ytPe/z4dqfakbsMpgaGWnLRUnTa0M3icdjSMnJrpZKUKACAqCCiDmNfn16sff6NVW6r14e7GYPk5IzJ0fWlhcC5H1yDiTGGiKQDAegSUQaiusVVrttXoj+/X6kBLm6TO4ZirL8hT+aWj9J1RQ5n3AQCIawSUQcIwDG3+8qBWbq7WG59/q8D81RGZTl1fWqiflBRoeIbT2koCABAiAsog8E2TR3NWvq9P69zBskvPPEXll47Sleedys3eAAAJh4CS4Pa5Pbr+d1v11YHDSku1a+rfjNRPLxmlMadmWF01AADCRkBJYPubvbruaDg5LdulP950iUYOHWJ1tQAAOGH0/SeoAy1eXf+7rfpy/2HlZzm1di7hBAAweBBQEtChw22a9dQ2fbGvRSMynXp27iUqyCGcAAAGDwJKgmk43KaZT23Trm+aNTzDoWfnXqJRp6RZXS0AACKKgJJAmo60a9bybfq83q3c9M5wckYu4QQAMPgQUBJEU2u7fvr7bfq0zq3c9FQ9+4+lOmtYutXVAgAgKggoCcDtaVf577frf/Y0KSctVWt+dgnLiAEAgxoBJc61eH2a/fvt+qi2UdlDUrTmZ6U6ewThBAAwuBFQ4thhr083rtiuD3c3KsuVomfmlOrcvEyrqwUAQNQRUOLUkTafbnz6fb1f3aAMZ7KemVOqcadlWV0tAABigoASpxa+8LG2f31IGY5krZ5TqgtGEk4AACcPAkoc2v71Ib30UZ2SbNLvbxyv4oJsq6sEAEBMEVDiTEeHoV+v/0ySNGN8gcafnmNxjQAAiD0CSpxZt2OvPt7bpHRHsn75d2dbXR0AACxBQIkjR9p8+rfXd0mSbv7eaA3LcFhcIwAArEFAiSP/sekrfev2auRQl278P6dbXR0AACxDQIkT9U2tWvbfX0qS/t/kc+VMsVtcIwAArENAiRP/9tr/ytPeoZLTc3T1uBFWVwcAAEsRUOLAztpGrduxV5J05w/Olc1ms7hGAABYi4BiMcM4tqx46sUjVTQy29oKAQAQBwgoFlv/P/X6S02DXCl2LbiKZcUAAEgEFEt52v36zaudy4r/73fP0qmZTotrBABAfCCgWGj5u19rb2Or8rKcmjvxTKurAwBA3CCgWGRfs0ePb/yrJGnhVefIlcqyYgAAAggoFnno9SodbvPrwoJs/fDCfKurAwBAXCGgWOCTvU167i+1kqRf/eBcJSWxrBgAgK4IKDFmGIbue/kzGYY05cJ8/c0o7lYMAEBPBJQY+6/PvtXWrw7JkZykhSwrBgCgTwSUGPL6/Hrglc8lST/72zM0cugQi2sEAEB8IqDE0KrNNao5eETDMhz6+eWjra4OAABxi4ASI41H2vToW19Ikv550tlKdyRbXCMAAOIXASVGtnx5UM0en87MTdPUvxlpdXUAAIhrBJQYqT54RJJUNDJLdpYVAwBwXKYDitfr1cKFC5Wfny+Xy6XS0lJt2LAhpGPXrl2riy++WE6nU8OGDdOcOXN04MAB05VORLsPHZYkFZ6SZnFNAACIf6YDyuzZs7V06VLNnDlTjzzyiOx2uyZPnqx33333uMc98cQTuu6665STk6OlS5fqH//xH7V27VpdccUV8ng8YZ9Aoqg+0NmDcvoprNwBAGAgNsMwjFBfvH37dpWWlmrJkiWaP3++JMnj8WjcuHEaPny4Nm/e3OdxbW1tOvXUU1VUVKS3335bNlvnEMf69es1ZcoUPfroo5o3b17IlXa73crKylJTU5MyMzNDPs5K/+c3b2lvY6te+PkE/c2ooVZXBwCAmDNz/TbVg1JZWSm73a65c+cGy5xOp+bMmaMtW7aotra2z+M++eQTNTY2asaMGcFwIkk/+MEPlJ6errVr15qpRsLx+vyqa2qVJI2iBwUAgAGZCig7duzQ2LFje6WekpISSdLOnTv7PM7r9UqSXC5Xr+dcLpd27Nihjo4OM1VJKLWHWmUYUrojWaekpVpdHQAA4p6pgFJfX6+8vLxe5YGyurq6Po8bM2aMbDab3nvvvW7l//u//6v9+/ertbVVDQ0N/b6v1+uV2+3u9kgkNQePTpDNGdKtBwkAAPTNVEBpbW2Vw+HoVe50OoPP9yU3N1fTp0/XypUr9dBDD+mrr77SO++8oxkzZiglJeW4x0rS4sWLlZWVFXwUFBSYqbblAkuMT89leAcAgFCYCigulys4XNNVYBVOX0M4AU8++aQmT56s+fPn66yzztLEiRN1wQUXaMqUKZKk9PT0fo+tqKhQU1NT8NHfXJd4tTvYg8ISYwAAQmFqv/W8vDzt3bu3V3l9fb0kKT8/v99js7Ky9Oc//1m7d+9WdXW1Ro0apVGjRmnChAkaNmyYsrOz+z3W4XD02XOTKII9KEyQBQAgJKYCSnFxsTZu3Ci3291touy2bduCzw+ksLBQhYWFkqTGxkb95S9/0dSpU81UI+HsPtQZUEaxSRsAACExNcRTVlYmv9+vZcuWBcu8Xq9WrFih0tLS4NyQ3bt3a9euXQP+voqKCvl8Pt1+++0mq504fP4O1QYDCj0oAACEwlQPSmlpqaZNm6aKigrt27dPo0eP1sqVK1VdXa3ly5cHX1deXq5Nmzap6x5wv/nNb/TJJ5+otLRUycnJ+s///E/913/9l+677z6NHz8+cmcUZ+qbPPJ1GEpNTtKITKfV1QEAICGYCiiStGrVKi1atEirV69WQ0ODioqKtH79ek2cOPG4x11wwQVat26dXnzxRfn9fhUVFem5557TtGnTwq58IqjussQ4iZsEAgAQElNb3ceLRNrq/pmtNbrzPz/RlecO11M3DN6eIgAABhK1re5hXg1LjAEAMI2AEmVs0gYAgHkElCjbfTSgFOYQUAAACBUBJYoMw1DNoc4hntPZAwUAgJARUKJoX7NXnvYO2ZNsOm1o/7cBAAAA3RFQoqj6QGfvyWnZLqXY+VMDABAqrppRVMMOsgAAhIWAEkWBJcYEFAAAzCGgRFFN8C7GTJAFAMAMAkoU1bDEGACAsBBQosQwjOB9eE7PpQcFAAAzCChR0nikXc0enyR6UAAAMIuAEiWB3pMRmU45U+wW1wYAgMRCQImS3SwxBgAgbASUKKk+QEABACBcBJQoCdyDZxRLjAEAMI2AEiWBJcb0oAAAYB4BJUoCu8iySRsAAOYRUKKgxevTgZY2SVIhPSgAAJhGQImCQO9JTlqqMp0pFtcGAIDEQ0CJgt3MPwEA4IQQUKKgOhBQ2EEWAICwEFCiYDdLjAEAOCEElChgkzYAAE4MASUKjm1zTw8KAADhIKBEmKfdr7qmVkn0oAAAEC4CSoTtaTgiw5DSHck6JS3V6uoAAJCQCCgRFtjivjBniGw2m8W1AQAgMRFQIiywxPj0XIZ3AAAIFwElwnYfZIkxAAAnioASYWzSBgDAiSOgRBhLjAEAOHEElAjy+TtUe4hN2gAAOFEElAiqa/TI12EoNTlJIzKdVlcHAICERUCJoJqj9+ApzBmipCSWGAMAEC4CSgQFlxgzvAMAwAkhoEQQS4wBAIgMAkoEBZcY04MCAMAJIaBE0O6DLDEGACASCCgRYhhGcJIsm7QBAHBiCCgRsq/ZK097h+xJNp021GV1dQAASGgElAipPtDZe3Jatkspdv6sAACcCK6kEVLDBFkAACKGgBIhwfknBBQAAE4YASVCjm3SxgoeAABOFAElQlhiDABA5BBQIsAwDFUfZIgHAIBIIaBEQOORdjV7fJI6bxQIAABODAElAgK9JyMynXKm2C2uDQAAiY+AEgG7D7HEGACASCKgRED1AQIKAACRRECJgJrgBFlW8AAAEAkElAioOcQeKAAARBIBJQJqWGIMAEBEEVBOUIvXpwMtbZKkQgIKAAARQUA5QYHek5y0VGU6UyyuDQAAgwMB5QTt5i7GAABEnOmA4vV6tXDhQuXn58vlcqm0tFQbNmwI6dg33nhD3/ve95Sbm6vs7GyVlJRo9erVpisdTwI3CRzFDrIAAESM6YAye/ZsLV26VDNnztQjjzwiu92uyZMn69133z3ucS+++KImTZqktrY23X333br//vvlcrlUXl6u3/72t2GfgNVYYgwAQOTZDMMwQn3x9u3bVVpaqiVLlmj+/PmSJI/Ho3Hjxmn48OHavHlzv8dOmjRJn376qb766is5HA5Jks/n0znnnKO0tDR99NFHIVfa7XYrKytLTU1NyszMDPm4aLhu2VZt+eqglk6/UNdePNLSugAAEM/MXL9N9aBUVlbKbrdr7ty5wTKn06k5c+Zoy5Ytqq2tPW6lhg4dGgwnkpScnKzc3Fy5XC4z1Ygr9KAAABB5pgLKjh07NHbs2F6pp6SkRJK0c+fOfo+9/PLL9emnn2rRokX661//qi+//FK//vWv9cEHH2jBggXHfV+v1yu3293tEQ887X7Vuz2SpNOZJAsAQMQkm3lxfX298vLyepUHyurq6vo9dtGiRfr66691//3367777pMkDRkyRC+88IJ+9KMfHfd9Fy9erHvuucdMVWNiT8MRGYaU7khWTlqq1dUBAGDQMNWD0tra2m2IJsDpdAaf74/D4dDYsWNVVlamZ599Vs8884y+853vaNasWdq6detx37eiokJNTU3Bx/GGkmKppssSY5vNZnFtAAAYPEz1oLhcLnm93l7lHo8n+Hx/fvGLX2jr1q368MMPlZTUmYumT5+u888/X7feequ2bdvW77EOh6PPYGS1avZAAQAgKkz1oOTl5am+vr5XeaAsPz+/z+Pa2tq0fPlyXXPNNcFwIkkpKSm6+uqr9cEHH6itrc1MVeLCbibIAgAQFaYCSnFxsaqqqnpNUg30fhQXF/d53MGDB+Xz+eT3+3s9197ero6Ojj6fi3ds0gYAQHSYCihlZWXy+/1atmxZsMzr9WrFihUqLS1VQUGBJGn37t3atWtX8DXDhw9Xdna21q1b162npKWlRS+99JLOOeechFxqvKehM6AUEFAAAIgoU3NQSktLNW3aNFVUVGjfvn0aPXq0Vq5cqerqai1fvjz4uvLycm3atEmBPeDsdrvmz5+vO++8U5dcconKy8vl9/u1fPly7dmzR88880xkzypGmj0+SVL2EG4SCABAJJkKKJK0atUqLVq0SKtXr1ZDQ4OKioq0fv16TZw48bjH3XHHHTrjjDP0yCOP6J577pHX61VRUZEqKys1derUsE/ASoGAwl2MAQCILFNb3ceLeNjqvt3foTF3vCpJ2rHo7zSUfVAAADiuqG11j2MOe33B79OdpjuiAADAcRBQwhQY3nGmJCnFzp8RAIBI4soaJrenXZKUwfwTAAAijoASppajPSgZDO8AABBxBJQwBYZ4MhwEFAAAIo2AEqZmL0M8AABECwElTAzxAAAQPQSUMLmPBpR0hngAAIg4AkqYgnNQGOIBACDiCChhagnOQaEHBQCASCOghKmZOSgAAEQNASVMBBQAAKKHgBKmFuagAAAQNQSUMAW2umcVDwAAkUdACRNDPAAARA8BJUwtXoZ4AACIFgJKGAzD6BJQ6EEBACDSCChhONLml7/DkERAAQAgGggoYQj0ntiTbHKl2C2uDQAAgw8BJQzNXVbw2Gw2i2sDAMDgQ0AJg5sVPAAARBUBJQwt3MkYAICoIqCEIbAHSiZLjAEAiAoCShi4kzEAANFFQAlDoAclnYACAEBUEFDCwCRZAACii4ASBu5kDABAdBFQwtDMnYwBAIgqAkoYjq3iIaAAABANBJQwcCdjAACii4ASBoZ4AACILgJKGJpZxQMAQFQRUMLQzBAPAABRRUAJQ2CIhx4UAACig4BiUru/Q572DkkEFAAAooWAYlJgkzaJSbIAAEQLAcWkwARZV4pdyXb+fAAARANXWJPczD8BACDqCCgmBTZp407GAABEDwHFpGZuFAgAQNQRUEwKLDHmPjwAAEQPAcWk4BAPK3gAAIgaAopJbHMPAED0EVBMOraKhzkoAABECwHFpMBGbQzxAAAQPQQUkxjiAQAg+ggoJgUmyWYyxAMAQNQQUEwKLDNmozYAAKKHgGISQzwAAEQfAcUkdpIFACD6CCgmBYd4WMUDAEDUEFBMMAyjyyRZAgoAANFCQDHhSJtfHUbn9wzxAAAQPQQUEwLzT+xJNjlT+NMBABAtXGVNaA5uc58sm81mcW0AABi8CCgmNHtZYgwAQCyYDiher1cLFy5Ufn6+XC6XSktLtWHDhgGPO/3002Wz2fp8jBkzJqzKx1pz8D48zD8BACCaTHcFzJ49W5WVlbrttts0ZswYPf3005o8ebI2btyoyy67rN/jHn74YbW0tHQrq6mp0Z133qlJkyaZr7kFug7xAACA6DF1pd2+fbvWrl2rJUuWaP78+ZKk8vJyjRs3TgsWLNDmzZv7PfYf/uEfepXdd999kqSZM2eaqYZlAncyzmAPFAAAosrUEE9lZaXsdrvmzp0bLHM6nZozZ462bNmi2tpaU2/+hz/8QWeccYYmTJhg6jirsM09AACxYSqg7NixQ2PHjlVmZma38pKSEknSzp07Tf2uzz//XNdff72ZKljq2BAPc1AAAIgmU10B9fX1ysvL61UeKKurqwv5d61Zs0ZSaMM7Xq9XXq83+LPb7Q75fSIpsIqHOxkDABBdpnpQWltb5XA4epU7nc7g86Ho6OjQ2rVrddFFF+ncc88d8PWLFy9WVlZW8FFQUGCm2hHDEA8AALFhKqC4XK5uPRkBHo8n+HwoNm3apL1794Y8ObaiokJNTU3Bh9m5LpHCEA8AALFhqisgLy9Pe/fu7VVeX18vScrPzw/p96xZs0ZJSUm67rrrQnq9w+Hos+cm1gI3CmQVDwAA0WWqB6W4uFhVVVW95oBs27Yt+PxAvF6vXnjhBV1++eUhB5p4wRAPAACxYSqglJWVye/3a9myZcEyr9erFStWqLS0NDg3ZPfu3dq1a1efv+OVV15RY2Njwux90tWxgMIQDwAA0WSqK6C0tFTTpk1TRUWF9u3bp9GjR2vlypWqrq7W8uXLg68rLy/Xpk2bZBhGr9+xZs0aORwOTZ069cRrH2PHtrqnBwUAgGgyfaVdtWqVFi1apNWrV6uhoUFFRUVav369Jk6cOOCxbrdbL7/8sq655hplZWWFVWErsdU9AACxYTP66uaIc263W1lZWWpqauq1aVy0tPk6NPbOVyVJH/1qkrKGMMwDAIAZZq7fpu9mfLIKrOCRpDSH3cKaAAAw+BFQQhQY3hmSaleynT8bAADRxJU2RCwxBgAgdggoIWIFDwAAsUNACRHb3AMAEDsElBAFt7lniAcAgKgjoISIOSgAAMQOASVEwSEeB0M8AABEGwElRM1Hh3jS6UEBACDqCCghYogHAIDYIaCEiDsZAwAQOwSUELUE56DQgwIAQLQRUELEEA8AALFDQAkRQzwAAMQOASVELaziAQAgZggoIXIHt7onoAAAEG0ElBB0dBhsdQ8AQAwRUEJwpN0vw+j8np1kAQCIPgJKCALb3Ccn2eRM4U8GAEC0cbUNQdclxjabzeLaAAAw+BFQQhAIKKzgAQAgNggoIeBOxgAAxBYBJQTsIgsAQGwRUELAEmMAAGKLgBKC4BAP29wDABATBJQQBCfJcidjAABigoASAuagAAAQWwSUEHAnYwAAYouAEoIWb+ccFPZBAQAgNggoIQj0oGQSUAAAiAkCSgiYgwIAQGwRUEIQ2AclnZ1kAQCICQJKCI7tg0IPCgAAsUBACYGbIR4AAGKKgDIAr8+vNl+HJG4WCABArBBQBtBytPdEYpkxAACxQkAZQGAFT1qqXfYkm8W1AQDg5EBAGUBwBQ+9JwAAxAwBZQBu7mQMAEDMEVAGwCZtAADEHgFlAIFJsukOAgoAALFCQBlAYJO2TIZ4AACIGQLKABjiAQAg9ggoAzh2Hx4CCgAAsUJAGcCxbe4Z4gEAIFYIKAMIzEFhHxQAAGKHgDKAwBAPc1AAAIgdAsoAApNkMwkoAADEDAFlAMEhHu5kDABAzBBQBtDCMmMAAGKOgDIA9kEBACD2CCjH0dFhqKWNuxkDABBrBJTjONzmk2F0fs9W9wAAxA4B5TgCwzspdpscyfypAACIFa66x9F1m3ubzWZxbQAAOHkQUI4jsMSYbe4BAIgtAspxuFnBAwCAJUwHFK/Xq4ULFyo/P18ul0ulpaXasGFDyMf/8Y9/1KWXXqq0tDRlZ2drwoQJeuutt8xWIyYCe6BwJ2MAAGLLdECZPXu2li5dqpkzZ+qRRx6R3W7X5MmT9e677w547N13363rrrtOBQUFWrp0qe677z4VFRVp7969YVU+2pq5kzEAAJYw1TWwfft2rV27VkuWLNH8+fMlSeXl5Ro3bpwWLFigzZs393vs1q1bde+99+qhhx7S7bfffmK1jpHAHBTuwwMAQGyZ6kGprKyU3W7X3Llzg2VOp1Nz5szRli1bVFtb2++xDz/8sEaMGKFbb71VhmGopaUl/FrHSHAVDwEFAICYMhVQduzYobFjxyozM7NbeUlJiSRp586d/R775ptvavz48Xr00Uc1bNgwZWRkKC8vT4899tiA7+v1euV2u7s9YoFt7gEAsIapK299fb3y8vJ6lQfK6urq+jyuoaFBBw4c0Hvvvae33npLd911lwoLC7VixQrNmzdPKSkpuummm/p938WLF+uee+4xU9WIcLPMGAAAS5jqQWltbZXD4ehV7nQ6g8/3JTCcc/DgQT311FOaP3++pk+frpdfflnnnXee7rvvvuO+b0VFhZqamoKP4w0lRRKreAAAsIapgOJyueT1enuVezye4PP9HSdJKSkpKisrO/bmSUmaMWOG9uzZo927d/f7vg6HQ5mZmd0escAQDwAA1jAVUPLy8lRfX9+rPFCWn5/f53E5OTlyOp065ZRTZLfbuz03fPhwSZ3DQPGm2RsY4iGgAAAQS6YCSnFxsaqqqnpNUt22bVvw+T7fJClJxcXF2r9/v9ra2ro9F5i3MmzYMDNViYkW9kEBAMASpgJKWVmZ/H6/li1bFizzer1asWKFSktLVVBQIEnavXu3du3a1e3YGTNmyO/3a+XKlcEyj8ejNWvW6Lzzzuu398VKDPEAAGANU1fe0tJSTZs2TRUVFdq3b59Gjx6tlStXqrq6WsuXLw++rry8XJs2bZJhGMGym266SU899ZRuvvlmVVVVqbCwUKtXr1ZNTY1eeumlyJ1RBDUzSRYAAEuYvvKuWrVKixYt0urVq9XQ0KCioiKtX79eEydOPO5xLpdLb731lhYsWKDf//73Onz4sIqLi/Xyyy/r7//+78M+gWjx+vxq83dIYogHAIBYsxlduzkShNvtVlZWlpqamqK2oudAi1ffue8NSdKXD0yWPckWlfcBAOBkYeb6bfpmgSeLwPBOWqqdcAIAQIwRUPrBCh4AAKxDQOlHs4c9UAAAsAoBpR9uD3cyBgDAKgSUfrR4GeIBAMAqBJR+MMQDAIB1CCj9CE6SZZM2AABijoDSj2Yv29wDAGAVAko/jg3xMAcFAIBYI6D0g/vwAABgHQJKP7iTMQAA1iGg9IMhHgAArENA6UcLk2QBALAMAaUfDPEAAGAdAko/mCQLAIB1CCh96Ogw2OoeAAALEVD60NLmC37PEA8AALFHQOlDYHgnxW6TI5k/EQAAscbVtw/B+/A4U2Sz2SyuDQAAJx8CSh+4kzEAANYioPSBFTwAAFiLgNIH7mQMAIC1CCh9YJt7AACsRUDpQ3AXWYZ4AACwBAGlDy1scw8AgKUIKH1giAcAAGsRUPoQXMVDDwoAAJYgoPSBVTwAAFiLgNIHhngAALAWAaUPrOIBAMBaBJQ+tDDEAwCApQgofWCSLAAA1iKg9KHr3YwBAEDsEVB68LT71ebvkMQQDwAAViGg9BAY3pGktFQCCgAAViCg9BCYIJvuSJY9yWZxbQAAODkRUHo4tgcKvScAAFiFgNJDcAUPe6AAAGAZAkoPzdzJGAAAyxFQemCbewAArEdA6YFN2gAAsB4BpYfAKp5MAgoAAJYhoPTAEA8AANYjoPTAKh4AAKxHQOmhmTsZAwBgOQJKD83cKBAAAMsRUHoIzEFhiAcAAOsQUHpo8bCKBwAAqxFQemCIBwAA6xFQeggO8dCDAgCAZQgoXfg7DB1u80tiFQ8AAFYioHQR2EVWYpIsAABWIqB0ERjeSbUnyZlit7g2AACcvAgoXbSwSRsAAHGBgNIFdzIGACA+EFC6aPHQgwIAQDwwHVC8Xq8WLlyo/Px8uVwulZaWasOGDQMed/fdd8tms/V6OJ3OsCoeDe7AnYwd7IECAICVTHcVzJ49W5WVlbrttts0ZswYPf3005o8ebI2btyoyy67bMDjn3jiCaWnpwd/ttvjZzIqQzwAAMQHU1fi7du3a+3atVqyZInmz58vSSovL9e4ceO0YMECbd68ecDfUVZWptzc3PBqG2XjTsvSvO+P1pnD0qyuCgAAJzVTQzyVlZWy2+2aO3dusMzpdGrOnDnasmWLamtrB/wdhmHI7XbLMAzztY2y4oJs/dOks/Xji0ZaXRUAAE5qpgLKjh07NHbsWGVmZnYrLykpkSTt3LlzwN9x5plnKisrSxkZGZo1a5a+/fbbAY/xer1yu93dHgAAYPAyNcRTX1+vvLy8XuWBsrq6un6PHTp0qH7xi1/o0ksvlcPh0DvvvKN///d/1/bt2/XBBx/0Cj1dLV68WPfcc4+ZqgIAgARmKqC0trbK4XD0Kg+sxGltbe332FtvvbXbz1OnTlVJSYlmzpypxx9/XP/yL//S77EVFRX65S9/GfzZ7XaroKDATNUBAEACMTXE43K55PV6e5V7PJ7g82Zcf/31GjFihN54443jvs7hcCgzM7PbAwAADF6mAkpeXp7q6+t7lQfK8vPzTVegoKBAhw4dMn0cAAAYvEwFlOLiYlVVVfWapLpt27bg82YYhqHq6moNGzbM1HEAAGBwMxVQysrK5Pf7tWzZsmCZ1+vVihUrVFpaGpwXsnv3bu3atavbsfv37+/1+5544gnt379fV111VTh1BwAAg5SpSbKlpaWaNm2aKioqtG/fPo0ePVorV65UdXW1li9fHnxdeXm5Nm3a1G2vk1GjRmnGjBm64IIL5HQ69e6772rt2rUqLi7WTTfdFLkzAgAACc/0nu6rVq3SokWLtHr1ajU0NKioqEjr16/XxIkTj3vczJkztXnzZr3wwgvyeDwaNWqUFixYoDvuuENDhgwJ+wQAAMDgYzPicUvXAbjdbmVlZampqYkVPQAAJAgz12/TdzMGAACINgIKAACIOwQUAAAQd0xPko0HgWkz3DQQAIDEEbhuhzL9NSEDSnNzsyRxPx4AABJQc3OzsrKyjvuahFzF09HRobq6OmVkZMhms0X0dwduRFhbWztoVwidDOcocZ6DDec5eJwM5yhxnn0xDEPNzc3Kz89XUtLxZ5kkZA9KUlKSRo4cGdX3OBluSngynKPEeQ42nOfgcTKco8R59jRQz0kAk2QBAEDcIaAAAIC4Q0DpweFw6K677pLD4bC6KlFzMpyjxHkONpzn4HEynKPEeZ6ohJwkCwAABjd6UAAAQNwhoAAAgLhDQAEAAHGHgAIAAOIOAQUAAMQdAspRXq9XCxcuVH5+vlwul0pLS7VhwwarqxUxb7/9tmw2W5+PrVu3Wl29sLW0tOiuu+7SVVddpZycHNlsNj399NN9vvbzzz/XVVddpfT0dOXk5OinP/2p9u/fH9sKhyHUc5w9e3af7XvOOefEvtJheP/99/WLX/xC559/vtLS0lRYWKjp06erqqqq12sTtS1DPcdEb8tPP/1U06ZN05lnnqkhQ4YoNzdXEydO1EsvvdTrtYnallLo55no7dnT/fffL5vNpnHjxvV6bvPmzbrssss0ZMgQjRgxQrfccotaWlrCep+E3Oo+GmbPnq3KykrddtttGjNmjJ5++mlNnjxZGzdu1GWXXWZ19SLmlltu0fjx47uVjR492qLanLgDBw7o3nvvVWFhoS688EK9/fbbfb5uz549mjhxorKysvTAAw+opaVFDz74oD7++GNt375dqampsa24CaGeo9S5H8FTTz3VrSzUbaWt9q//+q967733NG3aNBUVFembb77RY489posvvlhbt24N/s8wkdsy1HOUErsta2pq1NzcrBtuuEH5+fk6cuSIXnjhBf3whz/Uk08+qblz50pK7LaUQj9PKbHbs6s9e/bogQceUFpaWq/ndu7cqSuuuELnnnuuli5dqj179ujBBx/UF198oVdffdX8mxkwtm3bZkgylixZEixrbW01zjrrLOPSSy+1sGaRs3HjRkOS8fzzz1tdlYjyeDxGfX29YRiG8f777xuSjBUrVvR63c9//nPD5XIZNTU1wbINGzYYkownn3wyVtUNS6jneMMNNxhpaWkxrl3kvPfee4bX6+1WVlVVZTgcDmPmzJnBskRuy1DPMdHbsi8+n8+48MILjbPPPjtYlsht2Z++znMwteeMGTOM73//+8Z3v/td4/zzz+/23NVXX23k5eUZTU1NwbLf/e53hiTj9ddfN/1eDPFIqqyslN1u75Z2nU6n5syZoy1btqi2ttbC2kVec3OzfD6f1dWICIfDoREjRgz4uhdeeEE/+MEPVFhYGCy78sorNXbsWD333HPRrOIJC/UcA/x+v9xudxRrFB0TJkzo9Yl5zJgxOv/88/X5558HyxK5LUM9x4BEbcu+2O12FRQUqLGxMViWyG3Zn77OMyDR2/O///u/VVlZqYcffrjXc263Wxs2bNCsWbO63TCwvLxc6enpYbUnAUXSjh07NHbs2F53YSwpKZHU2W01WNx4443KzMyU0+nU9773PX3wwQdWVynq9u7dq3379uk73/lOr+dKSkq0Y8cOC2oVHUeOHFFmZqaysrKUk5Ojm2++Oezx33hgGIa+/fZb5ebmShqcbdnzHAMGQ1sePnxYBw4c0Jdffqnf/va3evXVV3XFFVdIGlxtebzzDEj09vT7/Zo3b55+9rOf6YILLuj1/Mcffyyfz9erPVNTU1VcXBxWezIHRVJ9fb3y8vJ6lQfK6urqYl2liEtNTdXUqVM1efJk5ebm6rPPPtODDz6ov/3bv9XmzZt10UUXWV3FqKmvr5ekftv40KFD8nq9CX+/jLy8PC1YsEAXX3yxOjo69Nprr+nxxx/XRx99pLffflvJyYn3n/uaNWu0d+9e3XvvvZIGZ1v2PEdp8LTlP/3TP+nJJ5+UJCUlJenaa6/VY489JmlwteXxzlMaHO35H//xH6qpqdEbb7zR5/MDtec777xj+j3j/68SA62trX3+R+B0OoPPJ7oJEyZowoQJwZ9/+MMfqqysTEVFRaqoqNBrr71mYe2iK9B+A7VxIvyP8HgWL17c7eef/OQnGjt2rO644w5VVlbqJz/5iUU1C8+uXbt0880369JLL9UNN9wgafC1ZV/nKA2etrzttttUVlamuro6Pffcc/L7/Wpra5M0uNryeOcpJX57Hjx4UL/61a+0aNEiDRs2rM/XDNSe4VxHGeKR5HK55PV6e5V7PJ7g84PR6NGj9aMf/UgbN26U3++3ujpRE2i/k7GNb7/9diUlJfX7qSdeffPNN7rmmmuUlZUVnCMmDa627O8c+5OIbXnOOefoyiuvVHl5udavX6+WlhZNmTJFhmEMqrY83nn2J5Ha884771ROTo7mzZvX72sGas9w2pKAos7up0D3VFeBsvz8/FhXKWYKCgrU1tamw4cPW12VqAl0OfbXxjk5OQnxKS0cLpdLp5xyig4dOmR1VULW1NSkq6++Wo2NjXrttde6/fc3WNryeOfYn0Rsy57Kysr0/vvvq6qqatC0ZV+6nmd/EqU9v/jiCy1btky33HKL6urqVF1drerqank8HrW3t6u6ulqHDh0asD3DuY4SUCQVFxerqqqq1+zqbdu2BZ8frL766is5nU6lp6dbXZWoOe200zRs2LA+JwRv3759ULdvc3OzDhw40G+3bLzxeDyaMmWKqqqqtH79ep133nndnh8MbTnQOfYn0dqyL4Fu/qampkHRlv3pep79SZT23Lt3rzo6OnTLLbfojDPOCD62bdumqqoqnXHGGbr33ns1btw4JScn92rPtrY27dy5M6z2JKCoM+36/X4tW7YsWOb1erVixQqVlpaqoKDAwtpFRl87M3700Ud68cUXNWnSJCUlDe5/ClOnTtX69eu7LRl/8803VVVVpWnTpllYs8jweDxqbm7uVf7rX/9ahmHoqquusqBW5vj9fs2YMUNbtmzR888/r0svvbTP1yVyW4ZyjoOhLfft29errL29XatWrZLL5QqGskRuSym080z09hw3bpzWrVvX63H++eersLBQ69at05w5c5SVlaUrr7xSzzzzTLfzXb16tVpaWsJqT5txvEGyk8j06dO1bt063X777Ro9erRWrlyp7du3680339TEiROtrt4J+/73vy+Xy6UJEyZo+PDh+uyzz7Rs2TKlpKRoy5YtOvfcc62uYtgee+wxNTY2qq6uTk888YSuvfba4KqkefPmKSsrS7W1tbrooouUnZ2tW2+9VS0tLVqyZIlGjhyp999/P+67kgc6x4aGBl100UW67rrrgttnv/7663rllVd01VVX6eWXX477EHrbbbfpkUce0ZQpUzR9+vRez8+aNUuSErotQznH6urqhG/LH//4x3K73Zo4caJOO+00ffPNN1qzZo127dqlhx56SL/85S8lJXZbSqGd52Boz75cfvnlOnDggD755JNg2YcffqgJEybovPPO09y5c7Vnzx499NBDmjhxol5//XXzbxLubnKDTWtrqzF//nxjxIgRhsPhMMaPH2+89tprVlcrYh555BGjpKTEyMnJMZKTk428vDxj1qxZxhdffGF11U7YqFGjDEl9Pr7++uvg6z755BNj0qRJxpAhQ4zs7Gxj5syZxjfffGNdxU0Y6BwbGhqMWbNmGaNHjzaGDBliOBwO4/zzzzceeOABo62tzerqh+S73/1uv+fY839VidqWoZzjYGjLZ5991rjyyiuNU0891UhOTjaGDh1qXHnllcaf//znXq9N1LY0jNDOczC0Z1/62knWMAzjnXfeMSZMmGA4nU5j2LBhxs0332y43e6w3oMeFAAAEHcSr18JAAAMegQUAAAQdwgoAAAg7hBQAABA3CGgAACAuENAAQAAcYeAAgAA4g4BBQAAxB0CCgAAiDsEFAAAEHcIKAAAIO4QUAAAQNz5/xrpvtRtZr78AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plotting the accuracy training, the x-axis is the epoch number and the y-axis is the accuracy\n",
    "plt.plot(L(learn.recorder.values).itemgot(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.065239</td>\n",
       "      <td>0.017955</td>\n",
       "      <td>0.995584</td>\n",
       "      <td>00:10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# let's try more layers with a pre trained model\n",
    "dls = ImageDataLoaders.from_folder(path_to_mnist_sample)\n",
    "learn = vision_learner(dls, resnet18, pretrained=False,\n",
    "    loss_func=F.cross_entropy, metrics=accuracy)\n",
    "learn.fit_one_cycle(1, 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See what we can do with fewer epochs and more layers ? That's impressive !"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
