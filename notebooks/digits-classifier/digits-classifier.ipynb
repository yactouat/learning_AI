{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Digits classifier\n",
    "\n",
    "Let's build a model that is able to recognize digits 3 and 7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading and setting up dependencies\n",
    "import fastbook\n",
    "\n",
    "fastbook.setup_book()\n",
    "\n",
    "from fastai.vision.all import *\n",
    "from fastbook import *\n",
    "from matplotlib import pyplot as plt\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#3) [Path('train'),Path('labels.csv'),Path('valid')]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import MNIST sample that only contains 3s and 7s\n",
    "path = untar_data(URLs.MNIST_SAMPLE)\n",
    "Path.BASE_PATH = path\n",
    "\n",
    "path.ls()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see from the previous output, this dataset is organized into separate folders for training and validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#2) [Path('train/3'),Path('train/7')]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's see what's inside the training set\n",
    "(path/'train').ls()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are confirming here that the training sample contains 7's and 3's only. These are our _labels_. Let's zoom in a little more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#6131) [Path('train/3/10.png'),Path('train/3/10000.png'),Path('train/3/10011.png'),Path('train/3/10031.png'),Path('train/3/10034.png'),Path('train/3/10042.png'),Path('train/3/10052.png'),Path('train/3/1007.png'),Path('train/3/10074.png'),Path('train/3/10091.png')...]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threes = (path/'train'/'3').ls().sorted()\n",
    "sevens = (path/'train'/'7').ls().sorted()\n",
    "threes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Images as array of numbers, e.g. tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/wAALCAAcABwBAREA/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/9oACAEBAAA/APCdP02+1a8W006znu7l+VigjLsQOpwO1dlb/CjVnkS3vNb8O6dqDkKtheaiFn3Hou1QcE8YBPcVg+LfCGqeCtYXS9WEPnvEJlML7lKEkA547qawatafqd/pN2LvTb24s7lQQJbeQowB6jI5r1D4Y6b4OvdXtdf8S+K45NY85phY3W6MeaCdrSTNw3IDcd8ZzyKx/i5pXiiLxMNZ8RC1kjvx/os1nJvh2KOFU8HgEHkc5zXntWdP0681a/hsbC3kubqY7Y4oxlmPXiu68OfBzxPq1yJNVtW0XTI/mnu73CbF74UkEn64HvVn4r+LdI1GDR/C3h2QzaTosXli5JJ858BeM9QAOvck9sV5nU1rdXFjdR3VpPLb3ETbo5YnKOh9QRyDV7UfE2v6vbi31PXNSvYA24RXN3JIufXDEjNZdFf/2Q==",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA9UlEQVR4AWNgGGSAEe4e2Upda8b/mwSvnloAF4MyDJY9+Pv31ZG/QPASTS72y8+/u/W4OFi4DiFLsoCV8XEyvCy9BGT++cfAsBlNJ7OICD9YSPvB369eaJJw7s+/X+vgHBQGX+r9vz9qUIRgHO5l74FO3S0H46PQAj9+gTzy4mo+E4o4lKOdlHQBJL9bDJssAwOncTlQ1ge7JAMD4/a/f7uhkhjm///PwHAXl87Qn3//quCQtLn29+9abuySSd///n3EiVVOa9ofYKSYostpFWvZFM//8Pfvr/WS6HIMu0GeB4KjYRhSDAzpYKkXzohUg0URtYQA/HZrR+ekLi0AAAAASUVORK5CYII=",
      "text/plain": [
       "<PIL.PngImagePlugin.PngImageFile image mode=L size=28x28>"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's look at one image\n",
    "im3_path = threes[1]\n",
    "im3 = Image.open(im3_path)\n",
    "im3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  29, 150, 195, 254, 255, 254, 176, 193, 150,  96,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  48, 166, 224, 253, 253, 234, 196, 253, 253, 253, 253, 233,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,  93, 244, 249, 253, 187,  46,  10,   8,   4,  10, 194, 253, 253, 233,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0, 107, 253, 253, 230,  48,   0,   0,   0,   0,   0, 192, 253, 253, 156,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   3,  20,  20,  15,   0,   0,   0,   0,   0,  43, 224, 253, 245,  74,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 249, 253, 245, 126,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  14, 101, 223, 253, 248, 124,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 166, 239, 253, 253, 253, 187,  30,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  16, 248, 250, 253, 253, 253, 253, 232, 213, 111,   2,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  43,  98,  98, 208, 253, 253, 253, 253, 187,  22,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   9,  51, 119, 253, 253, 253,  76,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   1, 183, 253, 253, 139,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 182, 253, 253, 104,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  85, 249, 253, 253,  36,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  60, 214, 253, 253, 173,  11,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  98, 247, 253, 253, 226,   9,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  42, 150, 252, 253, 253, 233,  53,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,  42, 115,  42,  60, 115, 159, 240, 253, 253, 250, 175,  25,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0, 187, 253, 253, 253, 253, 253, 253, 253, 197,  86,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0, 103, 253, 253, 253, 253, 253, 232,  67,   1,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]], dtype=uint8)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# viewing the numbers that make up that image as a `NumPy` array\n",
    "array(im3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,  29],\n",
       "       [  0,   0,   0,  48, 166, 224],\n",
       "       [  0,  93, 244, 249, 253, 187],\n",
       "       [  0, 107, 253, 253, 230,  48],\n",
       "       [  0,   3,  20,  20,  15,   0]], dtype=uint8)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# selecting a subarray from rows 4 to 10 (not included) and columns 4 to 10 (not included)\n",
    "# `numpy` indexes from top to bottom and left to right\n",
    "array(im3)[4:10,4:10] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now let's do the same thing with a `pytorch` tensor\n",
    "im3_t = tensor(im3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,  29],\n",
       "        [  0,   0,   0,  48, 166, 224],\n",
       "        [  0,  93, 244, 249, 253, 187],\n",
       "        [  0, 107, 253, 253, 230,  48],\n",
       "        [  0,   3,  20,  20,  15,   0]], dtype=torch.uint8)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor(im3)[4:10,4:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>150</td>\n",
       "      <td>195</td>\n",
       "      <td>254</td>\n",
       "      <td>255</td>\n",
       "      <td>254</td>\n",
       "      <td>176</td>\n",
       "      <td>193</td>\n",
       "      <td>150</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>48</td>\n",
       "      <td>166</td>\n",
       "      <td>224</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>234</td>\n",
       "      <td>196</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>233</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>93</td>\n",
       "      <td>244</td>\n",
       "      <td>249</td>\n",
       "      <td>253</td>\n",
       "      <td>187</td>\n",
       "      <td>46</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>194</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>233</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>107</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>230</td>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>192</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>156</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>224</td>\n",
       "      <td>253</td>\n",
       "      <td>245</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>249</td>\n",
       "      <td>253</td>\n",
       "      <td>245</td>\n",
       "      <td>126</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>101</td>\n",
       "      <td>223</td>\n",
       "      <td>253</td>\n",
       "      <td>248</td>\n",
       "      <td>124</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>166</td>\n",
       "      <td>239</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>187</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>248</td>\n",
       "      <td>250</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>232</td>\n",
       "      <td>213</td>\n",
       "      <td>111</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>98</td>\n",
       "      <td>98</td>\n",
       "      <td>208</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>253</td>\n",
       "      <td>187</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    0    1    2    3    4    5    6    7    8    9    10   11   12   13   14  \\\n",
       "0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0   \n",
       "1    0    0    0    0    0   29  150  195  254  255  254  176  193  150   96   \n",
       "2    0    0    0   48  166  224  253  253  234  196  253  253  253  253  233   \n",
       "3    0   93  244  249  253  187   46   10    8    4   10  194  253  253  233   \n",
       "4    0  107  253  253  230   48    0    0    0    0    0  192  253  253  156   \n",
       "5    0    3   20   20   15    0    0    0    0    0   43  224  253  245   74   \n",
       "6    0    0    0    0    0    0    0    0    0    0  249  253  245  126    0   \n",
       "7    0    0    0    0    0    0    0   14  101  223  253  248  124    0    0   \n",
       "8    0    0    0    0    0   11  166  239  253  253  253  187   30    0    0   \n",
       "9    0    0    0    0    0   16  248  250  253  253  253  253  232  213  111   \n",
       "10   0    0    0    0    0    0    0   43   98   98  208  253  253  253  253   \n",
       "\n",
       "     15  16  17  \n",
       "0     0   0   0  \n",
       "1     0   0   0  \n",
       "2     0   0   0  \n",
       "3     0   0   0  \n",
       "4     0   0   0  \n",
       "5     0   0   0  \n",
       "6     0   0   0  \n",
       "7     0   0   0  \n",
       "8     0   0   0  \n",
       "9     2   0   0  \n",
       "10  187  22   0  "
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's make a data frame out of the three image specimen tensor,\n",
    "# we'll only select the top part of the image\n",
    "df = pd.DataFrame(im3_t[4:15,4:22])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_bcca3_row0_col0, #T_bcca3_row0_col1, #T_bcca3_row0_col2, #T_bcca3_row0_col3, #T_bcca3_row0_col4, #T_bcca3_row0_col5, #T_bcca3_row0_col6, #T_bcca3_row0_col7, #T_bcca3_row0_col8, #T_bcca3_row0_col9, #T_bcca3_row0_col10, #T_bcca3_row0_col11, #T_bcca3_row0_col12, #T_bcca3_row0_col13, #T_bcca3_row0_col14, #T_bcca3_row0_col15, #T_bcca3_row0_col16, #T_bcca3_row0_col17, #T_bcca3_row1_col0, #T_bcca3_row1_col1, #T_bcca3_row1_col2, #T_bcca3_row1_col3, #T_bcca3_row1_col4, #T_bcca3_row1_col15, #T_bcca3_row1_col16, #T_bcca3_row1_col17, #T_bcca3_row2_col0, #T_bcca3_row2_col1, #T_bcca3_row2_col2, #T_bcca3_row2_col15, #T_bcca3_row2_col16, #T_bcca3_row2_col17, #T_bcca3_row3_col0, #T_bcca3_row3_col15, #T_bcca3_row3_col16, #T_bcca3_row3_col17, #T_bcca3_row4_col0, #T_bcca3_row4_col6, #T_bcca3_row4_col7, #T_bcca3_row4_col8, #T_bcca3_row4_col9, #T_bcca3_row4_col10, #T_bcca3_row4_col15, #T_bcca3_row4_col16, #T_bcca3_row4_col17, #T_bcca3_row5_col0, #T_bcca3_row5_col5, #T_bcca3_row5_col6, #T_bcca3_row5_col7, #T_bcca3_row5_col8, #T_bcca3_row5_col9, #T_bcca3_row5_col15, #T_bcca3_row5_col16, #T_bcca3_row5_col17, #T_bcca3_row6_col0, #T_bcca3_row6_col1, #T_bcca3_row6_col2, #T_bcca3_row6_col3, #T_bcca3_row6_col4, #T_bcca3_row6_col5, #T_bcca3_row6_col6, #T_bcca3_row6_col7, #T_bcca3_row6_col8, #T_bcca3_row6_col9, #T_bcca3_row6_col14, #T_bcca3_row6_col15, #T_bcca3_row6_col16, #T_bcca3_row6_col17, #T_bcca3_row7_col0, #T_bcca3_row7_col1, #T_bcca3_row7_col2, #T_bcca3_row7_col3, #T_bcca3_row7_col4, #T_bcca3_row7_col5, #T_bcca3_row7_col6, #T_bcca3_row7_col13, #T_bcca3_row7_col14, #T_bcca3_row7_col15, #T_bcca3_row7_col16, #T_bcca3_row7_col17, #T_bcca3_row8_col0, #T_bcca3_row8_col1, #T_bcca3_row8_col2, #T_bcca3_row8_col3, #T_bcca3_row8_col4, #T_bcca3_row8_col13, #T_bcca3_row8_col14, #T_bcca3_row8_col15, #T_bcca3_row8_col16, #T_bcca3_row8_col17, #T_bcca3_row9_col0, #T_bcca3_row9_col1, #T_bcca3_row9_col2, #T_bcca3_row9_col3, #T_bcca3_row9_col4, #T_bcca3_row9_col16, #T_bcca3_row9_col17, #T_bcca3_row10_col0, #T_bcca3_row10_col1, #T_bcca3_row10_col2, #T_bcca3_row10_col3, #T_bcca3_row10_col4, #T_bcca3_row10_col5, #T_bcca3_row10_col6, #T_bcca3_row10_col17 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #ffffff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_bcca3_row1_col5 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #efefef;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_bcca3_row1_col6, #T_bcca3_row1_col13 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #7c7c7c;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_bcca3_row1_col7 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #4a4a4a;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_bcca3_row1_col8, #T_bcca3_row1_col9, #T_bcca3_row1_col10, #T_bcca3_row2_col5, #T_bcca3_row2_col6, #T_bcca3_row2_col7, #T_bcca3_row2_col11, #T_bcca3_row2_col12, #T_bcca3_row2_col13, #T_bcca3_row3_col4, #T_bcca3_row3_col12, #T_bcca3_row3_col13, #T_bcca3_row4_col1, #T_bcca3_row4_col2, #T_bcca3_row4_col3, #T_bcca3_row4_col12, #T_bcca3_row4_col13, #T_bcca3_row5_col12, #T_bcca3_row6_col11, #T_bcca3_row9_col11, #T_bcca3_row10_col11, #T_bcca3_row10_col12, #T_bcca3_row10_col13, #T_bcca3_row10_col14, #T_bcca3_row10_col15, #T_bcca3_row10_col16 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #000000;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_bcca3_row1_col11 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #606060;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_bcca3_row1_col12 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #4d4d4d;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_bcca3_row1_col14 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #bbbbbb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_bcca3_row2_col3 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #e4e4e4;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_bcca3_row2_col4, #T_bcca3_row8_col6 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #6b6b6b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_bcca3_row2_col8, #T_bcca3_row2_col14, #T_bcca3_row3_col14 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #171717;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_bcca3_row2_col9, #T_bcca3_row3_col11 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #4b4b4b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_bcca3_row2_col10, #T_bcca3_row7_col10, #T_bcca3_row8_col8, #T_bcca3_row8_col10, #T_bcca3_row9_col8, #T_bcca3_row9_col10 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #010101;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_bcca3_row3_col1 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #272727;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_bcca3_row3_col2 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #0a0a0a;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_bcca3_row3_col3 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #050505;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_bcca3_row3_col5 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #333333;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_bcca3_row3_col6 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #e6e6e6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_bcca3_row3_col7, #T_bcca3_row3_col10 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #fafafa;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_bcca3_row3_col8 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #fbfbfb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_bcca3_row3_col9 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #fdfdfd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_bcca3_row4_col4 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #1b1b1b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_bcca3_row4_col5 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #e0e0e0;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_bcca3_row4_col11 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #4e4e4e;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_bcca3_row4_col14 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #767676;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_bcca3_row5_col1 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #fcfcfc;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_bcca3_row5_col2, #T_bcca3_row5_col3 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #f6f6f6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_bcca3_row5_col4, #T_bcca3_row7_col7 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #f8f8f8;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_bcca3_row5_col10, #T_bcca3_row10_col7 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #e8e8e8;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_bcca3_row5_col11 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #222222;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_bcca3_row5_col13, #T_bcca3_row6_col12 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #090909;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_bcca3_row5_col14 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #d0d0d0;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_bcca3_row6_col10, #T_bcca3_row7_col11, #T_bcca3_row9_col6 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #060606;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_bcca3_row6_col13 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #979797;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_bcca3_row7_col8 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #b6b6b6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_bcca3_row7_col9 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #252525;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_bcca3_row7_col12 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #999999;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_bcca3_row8_col5 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #f9f9f9;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_bcca3_row8_col7 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #101010;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_bcca3_row8_col9, #T_bcca3_row9_col9 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #020202;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_bcca3_row8_col11 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #545454;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_bcca3_row8_col12 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #f1f1f1;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_bcca3_row9_col5 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #f7f7f7;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_bcca3_row9_col7 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #030303;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_bcca3_row9_col12 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #181818;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_bcca3_row9_col13 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #303030;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_bcca3_row9_col14 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #a9a9a9;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_bcca3_row9_col15 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #fefefe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_bcca3_row10_col8, #T_bcca3_row10_col9 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #bababa;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_bcca3_row10_col10 {\n",
       "  font-size: 6pt;\n",
       "  background-color: #393939;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_bcca3\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_bcca3_level0_col0\" class=\"col_heading level0 col0\" >0</th>\n",
       "      <th id=\"T_bcca3_level0_col1\" class=\"col_heading level0 col1\" >1</th>\n",
       "      <th id=\"T_bcca3_level0_col2\" class=\"col_heading level0 col2\" >2</th>\n",
       "      <th id=\"T_bcca3_level0_col3\" class=\"col_heading level0 col3\" >3</th>\n",
       "      <th id=\"T_bcca3_level0_col4\" class=\"col_heading level0 col4\" >4</th>\n",
       "      <th id=\"T_bcca3_level0_col5\" class=\"col_heading level0 col5\" >5</th>\n",
       "      <th id=\"T_bcca3_level0_col6\" class=\"col_heading level0 col6\" >6</th>\n",
       "      <th id=\"T_bcca3_level0_col7\" class=\"col_heading level0 col7\" >7</th>\n",
       "      <th id=\"T_bcca3_level0_col8\" class=\"col_heading level0 col8\" >8</th>\n",
       "      <th id=\"T_bcca3_level0_col9\" class=\"col_heading level0 col9\" >9</th>\n",
       "      <th id=\"T_bcca3_level0_col10\" class=\"col_heading level0 col10\" >10</th>\n",
       "      <th id=\"T_bcca3_level0_col11\" class=\"col_heading level0 col11\" >11</th>\n",
       "      <th id=\"T_bcca3_level0_col12\" class=\"col_heading level0 col12\" >12</th>\n",
       "      <th id=\"T_bcca3_level0_col13\" class=\"col_heading level0 col13\" >13</th>\n",
       "      <th id=\"T_bcca3_level0_col14\" class=\"col_heading level0 col14\" >14</th>\n",
       "      <th id=\"T_bcca3_level0_col15\" class=\"col_heading level0 col15\" >15</th>\n",
       "      <th id=\"T_bcca3_level0_col16\" class=\"col_heading level0 col16\" >16</th>\n",
       "      <th id=\"T_bcca3_level0_col17\" class=\"col_heading level0 col17\" >17</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_bcca3_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_bcca3_row0_col0\" class=\"data row0 col0\" >0</td>\n",
       "      <td id=\"T_bcca3_row0_col1\" class=\"data row0 col1\" >0</td>\n",
       "      <td id=\"T_bcca3_row0_col2\" class=\"data row0 col2\" >0</td>\n",
       "      <td id=\"T_bcca3_row0_col3\" class=\"data row0 col3\" >0</td>\n",
       "      <td id=\"T_bcca3_row0_col4\" class=\"data row0 col4\" >0</td>\n",
       "      <td id=\"T_bcca3_row0_col5\" class=\"data row0 col5\" >0</td>\n",
       "      <td id=\"T_bcca3_row0_col6\" class=\"data row0 col6\" >0</td>\n",
       "      <td id=\"T_bcca3_row0_col7\" class=\"data row0 col7\" >0</td>\n",
       "      <td id=\"T_bcca3_row0_col8\" class=\"data row0 col8\" >0</td>\n",
       "      <td id=\"T_bcca3_row0_col9\" class=\"data row0 col9\" >0</td>\n",
       "      <td id=\"T_bcca3_row0_col10\" class=\"data row0 col10\" >0</td>\n",
       "      <td id=\"T_bcca3_row0_col11\" class=\"data row0 col11\" >0</td>\n",
       "      <td id=\"T_bcca3_row0_col12\" class=\"data row0 col12\" >0</td>\n",
       "      <td id=\"T_bcca3_row0_col13\" class=\"data row0 col13\" >0</td>\n",
       "      <td id=\"T_bcca3_row0_col14\" class=\"data row0 col14\" >0</td>\n",
       "      <td id=\"T_bcca3_row0_col15\" class=\"data row0 col15\" >0</td>\n",
       "      <td id=\"T_bcca3_row0_col16\" class=\"data row0 col16\" >0</td>\n",
       "      <td id=\"T_bcca3_row0_col17\" class=\"data row0 col17\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bcca3_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_bcca3_row1_col0\" class=\"data row1 col0\" >0</td>\n",
       "      <td id=\"T_bcca3_row1_col1\" class=\"data row1 col1\" >0</td>\n",
       "      <td id=\"T_bcca3_row1_col2\" class=\"data row1 col2\" >0</td>\n",
       "      <td id=\"T_bcca3_row1_col3\" class=\"data row1 col3\" >0</td>\n",
       "      <td id=\"T_bcca3_row1_col4\" class=\"data row1 col4\" >0</td>\n",
       "      <td id=\"T_bcca3_row1_col5\" class=\"data row1 col5\" >29</td>\n",
       "      <td id=\"T_bcca3_row1_col6\" class=\"data row1 col6\" >150</td>\n",
       "      <td id=\"T_bcca3_row1_col7\" class=\"data row1 col7\" >195</td>\n",
       "      <td id=\"T_bcca3_row1_col8\" class=\"data row1 col8\" >254</td>\n",
       "      <td id=\"T_bcca3_row1_col9\" class=\"data row1 col9\" >255</td>\n",
       "      <td id=\"T_bcca3_row1_col10\" class=\"data row1 col10\" >254</td>\n",
       "      <td id=\"T_bcca3_row1_col11\" class=\"data row1 col11\" >176</td>\n",
       "      <td id=\"T_bcca3_row1_col12\" class=\"data row1 col12\" >193</td>\n",
       "      <td id=\"T_bcca3_row1_col13\" class=\"data row1 col13\" >150</td>\n",
       "      <td id=\"T_bcca3_row1_col14\" class=\"data row1 col14\" >96</td>\n",
       "      <td id=\"T_bcca3_row1_col15\" class=\"data row1 col15\" >0</td>\n",
       "      <td id=\"T_bcca3_row1_col16\" class=\"data row1 col16\" >0</td>\n",
       "      <td id=\"T_bcca3_row1_col17\" class=\"data row1 col17\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bcca3_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_bcca3_row2_col0\" class=\"data row2 col0\" >0</td>\n",
       "      <td id=\"T_bcca3_row2_col1\" class=\"data row2 col1\" >0</td>\n",
       "      <td id=\"T_bcca3_row2_col2\" class=\"data row2 col2\" >0</td>\n",
       "      <td id=\"T_bcca3_row2_col3\" class=\"data row2 col3\" >48</td>\n",
       "      <td id=\"T_bcca3_row2_col4\" class=\"data row2 col4\" >166</td>\n",
       "      <td id=\"T_bcca3_row2_col5\" class=\"data row2 col5\" >224</td>\n",
       "      <td id=\"T_bcca3_row2_col6\" class=\"data row2 col6\" >253</td>\n",
       "      <td id=\"T_bcca3_row2_col7\" class=\"data row2 col7\" >253</td>\n",
       "      <td id=\"T_bcca3_row2_col8\" class=\"data row2 col8\" >234</td>\n",
       "      <td id=\"T_bcca3_row2_col9\" class=\"data row2 col9\" >196</td>\n",
       "      <td id=\"T_bcca3_row2_col10\" class=\"data row2 col10\" >253</td>\n",
       "      <td id=\"T_bcca3_row2_col11\" class=\"data row2 col11\" >253</td>\n",
       "      <td id=\"T_bcca3_row2_col12\" class=\"data row2 col12\" >253</td>\n",
       "      <td id=\"T_bcca3_row2_col13\" class=\"data row2 col13\" >253</td>\n",
       "      <td id=\"T_bcca3_row2_col14\" class=\"data row2 col14\" >233</td>\n",
       "      <td id=\"T_bcca3_row2_col15\" class=\"data row2 col15\" >0</td>\n",
       "      <td id=\"T_bcca3_row2_col16\" class=\"data row2 col16\" >0</td>\n",
       "      <td id=\"T_bcca3_row2_col17\" class=\"data row2 col17\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bcca3_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_bcca3_row3_col0\" class=\"data row3 col0\" >0</td>\n",
       "      <td id=\"T_bcca3_row3_col1\" class=\"data row3 col1\" >93</td>\n",
       "      <td id=\"T_bcca3_row3_col2\" class=\"data row3 col2\" >244</td>\n",
       "      <td id=\"T_bcca3_row3_col3\" class=\"data row3 col3\" >249</td>\n",
       "      <td id=\"T_bcca3_row3_col4\" class=\"data row3 col4\" >253</td>\n",
       "      <td id=\"T_bcca3_row3_col5\" class=\"data row3 col5\" >187</td>\n",
       "      <td id=\"T_bcca3_row3_col6\" class=\"data row3 col6\" >46</td>\n",
       "      <td id=\"T_bcca3_row3_col7\" class=\"data row3 col7\" >10</td>\n",
       "      <td id=\"T_bcca3_row3_col8\" class=\"data row3 col8\" >8</td>\n",
       "      <td id=\"T_bcca3_row3_col9\" class=\"data row3 col9\" >4</td>\n",
       "      <td id=\"T_bcca3_row3_col10\" class=\"data row3 col10\" >10</td>\n",
       "      <td id=\"T_bcca3_row3_col11\" class=\"data row3 col11\" >194</td>\n",
       "      <td id=\"T_bcca3_row3_col12\" class=\"data row3 col12\" >253</td>\n",
       "      <td id=\"T_bcca3_row3_col13\" class=\"data row3 col13\" >253</td>\n",
       "      <td id=\"T_bcca3_row3_col14\" class=\"data row3 col14\" >233</td>\n",
       "      <td id=\"T_bcca3_row3_col15\" class=\"data row3 col15\" >0</td>\n",
       "      <td id=\"T_bcca3_row3_col16\" class=\"data row3 col16\" >0</td>\n",
       "      <td id=\"T_bcca3_row3_col17\" class=\"data row3 col17\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bcca3_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_bcca3_row4_col0\" class=\"data row4 col0\" >0</td>\n",
       "      <td id=\"T_bcca3_row4_col1\" class=\"data row4 col1\" >107</td>\n",
       "      <td id=\"T_bcca3_row4_col2\" class=\"data row4 col2\" >253</td>\n",
       "      <td id=\"T_bcca3_row4_col3\" class=\"data row4 col3\" >253</td>\n",
       "      <td id=\"T_bcca3_row4_col4\" class=\"data row4 col4\" >230</td>\n",
       "      <td id=\"T_bcca3_row4_col5\" class=\"data row4 col5\" >48</td>\n",
       "      <td id=\"T_bcca3_row4_col6\" class=\"data row4 col6\" >0</td>\n",
       "      <td id=\"T_bcca3_row4_col7\" class=\"data row4 col7\" >0</td>\n",
       "      <td id=\"T_bcca3_row4_col8\" class=\"data row4 col8\" >0</td>\n",
       "      <td id=\"T_bcca3_row4_col9\" class=\"data row4 col9\" >0</td>\n",
       "      <td id=\"T_bcca3_row4_col10\" class=\"data row4 col10\" >0</td>\n",
       "      <td id=\"T_bcca3_row4_col11\" class=\"data row4 col11\" >192</td>\n",
       "      <td id=\"T_bcca3_row4_col12\" class=\"data row4 col12\" >253</td>\n",
       "      <td id=\"T_bcca3_row4_col13\" class=\"data row4 col13\" >253</td>\n",
       "      <td id=\"T_bcca3_row4_col14\" class=\"data row4 col14\" >156</td>\n",
       "      <td id=\"T_bcca3_row4_col15\" class=\"data row4 col15\" >0</td>\n",
       "      <td id=\"T_bcca3_row4_col16\" class=\"data row4 col16\" >0</td>\n",
       "      <td id=\"T_bcca3_row4_col17\" class=\"data row4 col17\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bcca3_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_bcca3_row5_col0\" class=\"data row5 col0\" >0</td>\n",
       "      <td id=\"T_bcca3_row5_col1\" class=\"data row5 col1\" >3</td>\n",
       "      <td id=\"T_bcca3_row5_col2\" class=\"data row5 col2\" >20</td>\n",
       "      <td id=\"T_bcca3_row5_col3\" class=\"data row5 col3\" >20</td>\n",
       "      <td id=\"T_bcca3_row5_col4\" class=\"data row5 col4\" >15</td>\n",
       "      <td id=\"T_bcca3_row5_col5\" class=\"data row5 col5\" >0</td>\n",
       "      <td id=\"T_bcca3_row5_col6\" class=\"data row5 col6\" >0</td>\n",
       "      <td id=\"T_bcca3_row5_col7\" class=\"data row5 col7\" >0</td>\n",
       "      <td id=\"T_bcca3_row5_col8\" class=\"data row5 col8\" >0</td>\n",
       "      <td id=\"T_bcca3_row5_col9\" class=\"data row5 col9\" >0</td>\n",
       "      <td id=\"T_bcca3_row5_col10\" class=\"data row5 col10\" >43</td>\n",
       "      <td id=\"T_bcca3_row5_col11\" class=\"data row5 col11\" >224</td>\n",
       "      <td id=\"T_bcca3_row5_col12\" class=\"data row5 col12\" >253</td>\n",
       "      <td id=\"T_bcca3_row5_col13\" class=\"data row5 col13\" >245</td>\n",
       "      <td id=\"T_bcca3_row5_col14\" class=\"data row5 col14\" >74</td>\n",
       "      <td id=\"T_bcca3_row5_col15\" class=\"data row5 col15\" >0</td>\n",
       "      <td id=\"T_bcca3_row5_col16\" class=\"data row5 col16\" >0</td>\n",
       "      <td id=\"T_bcca3_row5_col17\" class=\"data row5 col17\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bcca3_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_bcca3_row6_col0\" class=\"data row6 col0\" >0</td>\n",
       "      <td id=\"T_bcca3_row6_col1\" class=\"data row6 col1\" >0</td>\n",
       "      <td id=\"T_bcca3_row6_col2\" class=\"data row6 col2\" >0</td>\n",
       "      <td id=\"T_bcca3_row6_col3\" class=\"data row6 col3\" >0</td>\n",
       "      <td id=\"T_bcca3_row6_col4\" class=\"data row6 col4\" >0</td>\n",
       "      <td id=\"T_bcca3_row6_col5\" class=\"data row6 col5\" >0</td>\n",
       "      <td id=\"T_bcca3_row6_col6\" class=\"data row6 col6\" >0</td>\n",
       "      <td id=\"T_bcca3_row6_col7\" class=\"data row6 col7\" >0</td>\n",
       "      <td id=\"T_bcca3_row6_col8\" class=\"data row6 col8\" >0</td>\n",
       "      <td id=\"T_bcca3_row6_col9\" class=\"data row6 col9\" >0</td>\n",
       "      <td id=\"T_bcca3_row6_col10\" class=\"data row6 col10\" >249</td>\n",
       "      <td id=\"T_bcca3_row6_col11\" class=\"data row6 col11\" >253</td>\n",
       "      <td id=\"T_bcca3_row6_col12\" class=\"data row6 col12\" >245</td>\n",
       "      <td id=\"T_bcca3_row6_col13\" class=\"data row6 col13\" >126</td>\n",
       "      <td id=\"T_bcca3_row6_col14\" class=\"data row6 col14\" >0</td>\n",
       "      <td id=\"T_bcca3_row6_col15\" class=\"data row6 col15\" >0</td>\n",
       "      <td id=\"T_bcca3_row6_col16\" class=\"data row6 col16\" >0</td>\n",
       "      <td id=\"T_bcca3_row6_col17\" class=\"data row6 col17\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bcca3_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_bcca3_row7_col0\" class=\"data row7 col0\" >0</td>\n",
       "      <td id=\"T_bcca3_row7_col1\" class=\"data row7 col1\" >0</td>\n",
       "      <td id=\"T_bcca3_row7_col2\" class=\"data row7 col2\" >0</td>\n",
       "      <td id=\"T_bcca3_row7_col3\" class=\"data row7 col3\" >0</td>\n",
       "      <td id=\"T_bcca3_row7_col4\" class=\"data row7 col4\" >0</td>\n",
       "      <td id=\"T_bcca3_row7_col5\" class=\"data row7 col5\" >0</td>\n",
       "      <td id=\"T_bcca3_row7_col6\" class=\"data row7 col6\" >0</td>\n",
       "      <td id=\"T_bcca3_row7_col7\" class=\"data row7 col7\" >14</td>\n",
       "      <td id=\"T_bcca3_row7_col8\" class=\"data row7 col8\" >101</td>\n",
       "      <td id=\"T_bcca3_row7_col9\" class=\"data row7 col9\" >223</td>\n",
       "      <td id=\"T_bcca3_row7_col10\" class=\"data row7 col10\" >253</td>\n",
       "      <td id=\"T_bcca3_row7_col11\" class=\"data row7 col11\" >248</td>\n",
       "      <td id=\"T_bcca3_row7_col12\" class=\"data row7 col12\" >124</td>\n",
       "      <td id=\"T_bcca3_row7_col13\" class=\"data row7 col13\" >0</td>\n",
       "      <td id=\"T_bcca3_row7_col14\" class=\"data row7 col14\" >0</td>\n",
       "      <td id=\"T_bcca3_row7_col15\" class=\"data row7 col15\" >0</td>\n",
       "      <td id=\"T_bcca3_row7_col16\" class=\"data row7 col16\" >0</td>\n",
       "      <td id=\"T_bcca3_row7_col17\" class=\"data row7 col17\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bcca3_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_bcca3_row8_col0\" class=\"data row8 col0\" >0</td>\n",
       "      <td id=\"T_bcca3_row8_col1\" class=\"data row8 col1\" >0</td>\n",
       "      <td id=\"T_bcca3_row8_col2\" class=\"data row8 col2\" >0</td>\n",
       "      <td id=\"T_bcca3_row8_col3\" class=\"data row8 col3\" >0</td>\n",
       "      <td id=\"T_bcca3_row8_col4\" class=\"data row8 col4\" >0</td>\n",
       "      <td id=\"T_bcca3_row8_col5\" class=\"data row8 col5\" >11</td>\n",
       "      <td id=\"T_bcca3_row8_col6\" class=\"data row8 col6\" >166</td>\n",
       "      <td id=\"T_bcca3_row8_col7\" class=\"data row8 col7\" >239</td>\n",
       "      <td id=\"T_bcca3_row8_col8\" class=\"data row8 col8\" >253</td>\n",
       "      <td id=\"T_bcca3_row8_col9\" class=\"data row8 col9\" >253</td>\n",
       "      <td id=\"T_bcca3_row8_col10\" class=\"data row8 col10\" >253</td>\n",
       "      <td id=\"T_bcca3_row8_col11\" class=\"data row8 col11\" >187</td>\n",
       "      <td id=\"T_bcca3_row8_col12\" class=\"data row8 col12\" >30</td>\n",
       "      <td id=\"T_bcca3_row8_col13\" class=\"data row8 col13\" >0</td>\n",
       "      <td id=\"T_bcca3_row8_col14\" class=\"data row8 col14\" >0</td>\n",
       "      <td id=\"T_bcca3_row8_col15\" class=\"data row8 col15\" >0</td>\n",
       "      <td id=\"T_bcca3_row8_col16\" class=\"data row8 col16\" >0</td>\n",
       "      <td id=\"T_bcca3_row8_col17\" class=\"data row8 col17\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bcca3_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_bcca3_row9_col0\" class=\"data row9 col0\" >0</td>\n",
       "      <td id=\"T_bcca3_row9_col1\" class=\"data row9 col1\" >0</td>\n",
       "      <td id=\"T_bcca3_row9_col2\" class=\"data row9 col2\" >0</td>\n",
       "      <td id=\"T_bcca3_row9_col3\" class=\"data row9 col3\" >0</td>\n",
       "      <td id=\"T_bcca3_row9_col4\" class=\"data row9 col4\" >0</td>\n",
       "      <td id=\"T_bcca3_row9_col5\" class=\"data row9 col5\" >16</td>\n",
       "      <td id=\"T_bcca3_row9_col6\" class=\"data row9 col6\" >248</td>\n",
       "      <td id=\"T_bcca3_row9_col7\" class=\"data row9 col7\" >250</td>\n",
       "      <td id=\"T_bcca3_row9_col8\" class=\"data row9 col8\" >253</td>\n",
       "      <td id=\"T_bcca3_row9_col9\" class=\"data row9 col9\" >253</td>\n",
       "      <td id=\"T_bcca3_row9_col10\" class=\"data row9 col10\" >253</td>\n",
       "      <td id=\"T_bcca3_row9_col11\" class=\"data row9 col11\" >253</td>\n",
       "      <td id=\"T_bcca3_row9_col12\" class=\"data row9 col12\" >232</td>\n",
       "      <td id=\"T_bcca3_row9_col13\" class=\"data row9 col13\" >213</td>\n",
       "      <td id=\"T_bcca3_row9_col14\" class=\"data row9 col14\" >111</td>\n",
       "      <td id=\"T_bcca3_row9_col15\" class=\"data row9 col15\" >2</td>\n",
       "      <td id=\"T_bcca3_row9_col16\" class=\"data row9 col16\" >0</td>\n",
       "      <td id=\"T_bcca3_row9_col17\" class=\"data row9 col17\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_bcca3_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "      <td id=\"T_bcca3_row10_col0\" class=\"data row10 col0\" >0</td>\n",
       "      <td id=\"T_bcca3_row10_col1\" class=\"data row10 col1\" >0</td>\n",
       "      <td id=\"T_bcca3_row10_col2\" class=\"data row10 col2\" >0</td>\n",
       "      <td id=\"T_bcca3_row10_col3\" class=\"data row10 col3\" >0</td>\n",
       "      <td id=\"T_bcca3_row10_col4\" class=\"data row10 col4\" >0</td>\n",
       "      <td id=\"T_bcca3_row10_col5\" class=\"data row10 col5\" >0</td>\n",
       "      <td id=\"T_bcca3_row10_col6\" class=\"data row10 col6\" >0</td>\n",
       "      <td id=\"T_bcca3_row10_col7\" class=\"data row10 col7\" >43</td>\n",
       "      <td id=\"T_bcca3_row10_col8\" class=\"data row10 col8\" >98</td>\n",
       "      <td id=\"T_bcca3_row10_col9\" class=\"data row10 col9\" >98</td>\n",
       "      <td id=\"T_bcca3_row10_col10\" class=\"data row10 col10\" >208</td>\n",
       "      <td id=\"T_bcca3_row10_col11\" class=\"data row10 col11\" >253</td>\n",
       "      <td id=\"T_bcca3_row10_col12\" class=\"data row10 col12\" >253</td>\n",
       "      <td id=\"T_bcca3_row10_col13\" class=\"data row10 col13\" >253</td>\n",
       "      <td id=\"T_bcca3_row10_col14\" class=\"data row10 col14\" >253</td>\n",
       "      <td id=\"T_bcca3_row10_col15\" class=\"data row10 col15\" >187</td>\n",
       "      <td id=\"T_bcca3_row10_col16\" class=\"data row10 col16\" >22</td>\n",
       "      <td id=\"T_bcca3_row10_col17\" class=\"data row10 col17\" >0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f5f63e622c0>"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now let's color code the values\n",
    "df.style.set_properties(**{'font-size':'6pt'}).background_gradient('Greys')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## getting on with our baseline model\n",
    "\n",
    "The _baseline_ of our classifier will be very simple, as it should be:\n",
    "\n",
    "- find the average pixel value for every pixel of the 3s\n",
    "- find the average pixel value for every pixel of the 7s\n",
    "\n",
    "This gives us group averages that we may call \"ideal\" 3s and 7s. We would first classify a digit as a 3 if the average pixel value of the digit is closer to the ideal 3 than to the ideal 7, and vice versa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6131, 6265)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create lists of tensors containing all 3s and 7s stacked together\n",
    "seven_tensors = [tensor(Image.open(o)) for o in sevens]\n",
    "three_tensors = [tensor(Image.open(o)) for o in threes]\n",
    "len(three_tensors),len(seven_tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 100x100 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Jupyter ships with a function called `show_image` that knows how to render a tensor as an image\n",
    "show_image(three_tensors[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## rank-3 tensors\n",
    "\n",
    "For every pixel position, we want to compute the average over all the images of the intensity of that pixel. \n",
    "\n",
    "To do this we first combine all the images in this list into a single three-dimensional tensor. \n",
    "\n",
    "The most common way to describe such a tensor is to call it a _rank-3 tensor_.\n",
    "\n",
    "See an example of what that might look like below:\n",
    "\n",
    "![rank-3 tensor.png](./rank-3-tensor.png)\n",
    "\n",
    "A rank-3 tensor is essentially a cube of numbers.\n",
    "\n",
    "To index a number of that tensor, you would need:\n",
    "\n",
    "- the layer\n",
    "- the row\n",
    "- the column\n",
    "\n",
    "### how did we conclude that we needed a rank-3 tensor?\n",
    "\n",
    "- Each image is a 2d matrix of pixels (rows and columns, e.g. a _rank-2 tensor_)\n",
    "- Each element in the matrix corresponds to a pixel intensity (a scalar value, e.g. a _rank-1 tensor_)\n",
    "- To ease computing of the average of each pixel intensity over all images, you would stack each of these matrices on top of each other: there you have it, a _rank-3 tensor_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6131, 28, 28])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's our images and cast our stacked tensors as float tensors for further computation\n",
    "# we also normalise our pixel values to be between 0 and 1 by dividing by 255\n",
    "stacked_sevens = torch.stack(seven_tensors).float()/255\n",
    "stacked_threes = torch.stack(three_tensors).float()/255\n",
    "\n",
    "# a _shape_ tells us the length of each axis of a tensor\n",
    "stacked_threes.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The previous output says to us: \"we have 6131 images, each of size 28x28 pixels\". \n",
    "\n",
    "We can define the _shape_ as **the size of each axis in a tensor**.\n",
    "\n",
    "As you may have noticed, we have also normalized the values of the pixels. We want all pixels to be between 0 and 1. By ensuring that all values are of similar scale, we improve the accuracy of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the _length_ of a tensor's shape is its _rank_\n",
    "len(stacked_threes.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# you could also get the rank of a tensor like so\n",
    "stacked_threes.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The _dimension_ 0 of our rank-3 tensor is the number of images.\n",
    "\n",
    "Here is how you would compute the average pixel intensity for each pixel position:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 100x100 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ideal3 = stacked_threes.mean(0)\n",
    "show_image(ideal3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 100x100 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# let's do the same thing for the 7s\n",
    "ideal7 = stacked_sevens.mean(0)\n",
    "show_image(ideal7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the baseline model\n",
    "\n",
    "Now that we have an idea of what our ideal 3 and 7 look like, we can try to classify our images. To test our baseline, we would pick an arbitrary number from the dataset and measure its distance from its _ideal_ representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 100x100 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# here is our sample number for our test\n",
    "a_3 = stacked_threes[1]\n",
    "show_image(a_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To calculate the distance from the baseline `3`, we can't just add up the differences in intensity between each of the pixels of both images. It is so because some differences would cancel out (light vs dark pixels), and that would be misleading as very different pixels could have a value of zero, which would mean \"no difference from the ideal digit representation\".\n",
    "\n",
    "There are two main ways data scientists measure distance in this context:\n",
    "\n",
    "- take the mean absolute value of differences: this is called _mean absolute difference_ or _L1 norm_\n",
    "- take the mean of the square of differences (which makes everything positive) and then take the square root (which undoes the squaring): this is called _root mean squared error_ or _L2 norm_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1114)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's try the `L1` norm\n",
    "dist3_l1 = (a_3 - ideal3).abs().mean()\n",
    "\n",
    "dist3_l1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.2021)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's try the `L2` norm now\n",
    "dist3_l2 = ((a_3 - ideal3)**2).mean().sqrt()\n",
    "\n",
    "dist3_l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1586)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's check if our arbitrary number is a 3 or a 7 using both methods\n",
    "\n",
    "# `L1` norm\n",
    "dist7_l1 = (a_3 - ideal7).abs().mean()\n",
    "dist7_l1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.3021)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we'll use the `L2` norm\n",
    "dist7_l2 = ((a_3 - ideal7)**2).mean().sqrt()\n",
    "dist7_l2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the little experiment we've just run, we can see that our baseline model predicts right in this particular case, as both results are greater for a 7 than they would have been for a 3.\n",
    "\n",
    "We could have done the same thing with `PyTorch`, which provides loss functions (among many other things), as shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1586)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist7_l1_torch = F.l1_loss(a_3.float(), ideal7)\n",
    "dist7_l1_torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.3021)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist7_l2_torch = F.mse_loss(a_3, ideal7).sqrt()\n",
    "dist7_l2_torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### L1 vs L2 norms\n",
    "\n",
    "The main difference between L1 norm and MSE is that the latter will penalize bigger mistakes more heavily than the former, which may be more lenient with small mistakes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining a metric for our baseline model\n",
    "\n",
    "A metric is a number that is calculated based on the predictions of our model, and the correct labels in our dataset, in order to tell us how good our model is.\n",
    "\n",
    "In practice, _accuracy_ is a common metric for classification models.\n",
    "\n",
    "- The _error rate_ in deep learning refers to the difference between the predicted output and the actual output of a neural network. It is a measure of how well the network is performing on a given task. In this context, _accuracy_ can be defined as `1.0 - error rate`.\n",
    "\n",
    "A metric is always calculated over a _validation_ set.\n",
    "\n",
    "To get a validation set, we need to remove some of the data of the training set entirely, so it's not seen by the model at all during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1010, 28, 28]), torch.Size([1028, 28, 28]))"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's create tensors for 3s and 7s using the MNIST validation set\n",
    "valid_3_tens = torch.stack([tensor(Image.open(o)) for o in (path/'valid'/'3').ls()])\n",
    "valid_3_tens = valid_3_tens.float()/255\n",
    "valid_7_tens = torch.stack([tensor(Image.open(o)) for o in (path/'valid'/'7').ls()])\n",
    "valid_7_tens = valid_7_tens.float()/255\n",
    "\n",
    "# here we divided both tensors by 255 to normalize the pixel values between 0 and 1\n",
    "# x images of size 28x28 pixels\n",
    "valid_3_tens.shape,valid_7_tens.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1114)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now let's write the function that will give use the MSE loss for a given image\n",
    "def mnist_mse_distance(a,b): return (a-b).abs().mean((-1,-2))\n",
    "mnist_mse_distance(a_3, ideal3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### why `mean((-1,-2))`\n",
    "\n",
    "The `mean` function in `PyTorch` can take a tuple of axes to take the mean of. \n",
    "In this case, we want to take the mean over the last two dimensions (in this case, the horizontal and vertical dimensions of an image).\n",
    "\n",
    "The tuple `(-1,-2)` represents a range of axes.\n",
    "\n",
    "This effectively allows us to make batch calculations on rank-3 tensors, as you will see in the example below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.1463, 0.1526, 0.1214,  ..., 0.1360, 0.1326, 0.1422]),\n",
       " torch.Size([1010]))"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# applying the same calculation for every image in our validation set\n",
    "valid_3_dist = mnist_mse_distance(valid_3_tens, ideal3)\n",
    "valid_3_dist, valid_3_dist.shape\n",
    "\n",
    "# for every image, we averaged the intensity of all pixels in that image;\n",
    "# we are left with a rank-1 tensor of a thousand numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`PyTorch` is so versatile it didn't even complain about shapes not matching and calculated the distance for each image instead !\n",
    "\n",
    "This is made possible because `PyTorch` uses _broadcasting_ under the hood: e.g. the ability expand a lower rank tensor to have the same size as a higher rank input tensor during a calculation. This is why this type of operation is possible:\n",
    "\n",
    "```python\n",
    "tensor([1,2,3]) + tensor(1) # tensor([2,3,4])\n",
    "```\n",
    "\n",
    "When applying the `abs()` function on a tensor, you get back a matrix of absolute values.\n",
    "\n",
    "Now let's continue with the function that determines if the number is a `3` or a `7`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(True), tensor(1.))"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def is_3(x): return mnist_mse_distance(x,ideal3) < mnist_mse_distance(x,ideal7)\n",
    "\n",
    "# let's test the function\n",
    "is_3(a_3), is_3(a_3).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([True, True, True,  ..., True, True, True])"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's do the same thing at scale\n",
    "is_3(valid_3_tens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1.,  ..., 1., 1., 1.])"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# again but as floats\n",
    "is_3(valid_3_tens).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9168)"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the mean of correct predictions\n",
    "accuracy_3s = is_3(valid_3_tens).float().mean()\n",
    "accuracy_3s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9854)"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's do the above steps for 7s\n",
    "accuracy_7s = (1 - is_3(valid_7_tens).float()).mean()\n",
    "accuracy_7s\n",
    "\n",
    "# we use the inverse here with `1 - is_3` because we want to know how many 7s we correctly identified (OR logic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can conclude from the above that we have a pretty good baseline for 2 numbers !\n",
    "\n",
    "However, we are limited by the fact that we need to classify more than 2 numbers. This is where _Stochastic Gradient Descent_ (SGD) comes in."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introducing SGD\n",
    "\n",
    "In our pixels similarity approach, we don't have any kind of weight assignment, or any way of improving our classifier based on testing the effectiveness of a weight assignment.\n",
    "\n",
    "### A little apart on weight assignment\n",
    "\n",
    "A neural network is a mathematical function that is extremely flexible and that depends on its weights. Neural networks are powerful tools because they can solve a very wide array of problems just by finding the right weights.\n",
    "\n",
    "Weights in an AI model are numerical values that define how strongly given inputs to a node or neuron influence its output, in other words, they are the _parameters_ that are learned during the training process.\n",
    "\n",
    "Using neural networks gives the operator enough flexibility to focus his efforts on training the model, e.g. finding good weights assignments.\n",
    "\n",
    "Weights are just variables, and a weight assignment is a particular choice of values for those variables. \n",
    "\n",
    "The program's inputs are values that it processes in order to produce its results, for instance, taking image pixels as inputs and returning the classification \"dog\" as a result. The program's weight assignments are other values that define how the program will operate.\n",
    "\n",
    "A traditional program takes input and outputs results, whereas a machine learning program takes inputs and weights to output its results. Another difference is that the _program_ is a set of conditionals, loops, etc. whereas the _model_ is a mathematical function that minimizes errors to improve its accuracy. This function:\n",
    "  - takes the inputs\n",
    "  - multiplies them by a set of weights (nowaydays called `parameters`)\n",
    "  - adds them up\n",
    "  - redoes this process\n",
    "  - once it's done, it takes all the negative numbers and replaces them with 0s\n",
    "  - it then takes these inputs to a next _layer_ and redoes the whole process\n",
    "\n",
    "This is how a deep learning model works, in contrast of a more classic program, which does not have weights.\n",
    "\n",
    "Adjusting the weights here should is done with the goal of maximizing the model's performance. This adjustment can be done automatically.\n",
    "\n",
    "As you can see, we also differentiate `results` from `performance`. For instance, the results can be the classification of an image, and the performance can be the accuracy of the classification.\n",
    "\n",
    "The _loss_ is what is used to provide a better set of weights to the model, e.g. the model should aim at making the loss smaller\n",
    "\n",
    "At some point, we can decide that a model is trained, that is we've chosen our favorite weight assignment; you will generally include the weights as part of the model at the end of this process. You can also note that a trained model can be treated like any other computer program when the training is over, this leverages powerful APIs. Another thing to note: once the model is trained, predicting (_inference_) is faster than training.  \n",
    "\n",
    "Weight assignment in deep learning is like giving each input a score that affects how much it influences the output. For example, if you have a neural network that predicts the price of a house based on its size and location, you might give more weight to the size than the location, because size is more important for the price. The weights are usually random numbers at first, but they change as the network learns from the data. The way you choose the initial weights can affect how well the network learns and performs.\n",
    "\n",
    "One way to choose the initial weights is to use some rules based on the type of function that each node uses to calculate its output. For example, some functions are like switches that turn on or off depending on the input, while others are like curves that smoothly change from low to high. Different rules work better for different functions, so you have to match them accordingly.\n",
    "\n",
    "_Stochastic gradient descent_ is a technique used to update the weights of a neural network in order to make it improve at any given task. Its power resides in the fact that it provides a way of finding weight values automatically."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using another approach to classify digits\n",
    "\n",
    "Now, back to our problem.\n",
    "\n",
    "Instead of trying to find the similarity between an image and an \"ideal image,\" we could instead look at each individual pixel and come up with a set of weights for each one.\n",
    "\n",
    "For instance, pixels toward the bottom right are not very likely to activate neurons for a 7, so they should have a low weight for a 7, but they are likely to be activated for an 8, so they should have a high weight for an 8. \n",
    "\n",
    "This can be represented as a function with a set of weight values for each possible category, for instance the probability of being the number 8 =>\n",
    "\n",
    "```python\n",
    "def pr_eight(image_vector, weights_vector): return (image_vector * weights_vector).sum()\n",
    "```\n",
    "\n",
    "Here, the image represented as a vector is basically \"all the rows stacked up end to end on a single long line\". With this kind of function, we just need some way to update the weights to make them better and better at distinguishing between digits: we want to find the specific values for the weights that cause the result of our function to be high for images that are actually 8s, and low for images that are not. Searching for the best weights is a way of searching for the best function that recognizes 8s.\n",
    "\n",
    "These are the steps that will turn our function into a machine learning classifier:\n",
    "\n",
    "1. _Initialize_ the weights with random values\n",
    "2. For each image, use these weights to predict whether it appears to be a 3 or a 7\n",
    "3. Based on these predictions, calculate how good the model is (its _loss_)\n",
    "4. Calculate the _gradient_, which measures for each weight, how changing that weight would change the loss; the gradients will tell us how much we have to change each weight to make our model better\n",
    "5. _Step_ (that is, _change_) all the weights based on the previous calculation\n",
    "    - A simple way to figure out whether a weight should be increased a bit, or decreased a bit, would be just to try it: increase the weight by a small amount, and see if the loss goes up or down. Once you find the correct direction, you could then change that amount by a bit more, and a bit less, until you find an amount that works well. However, this is slow! As we will see, the magic of calculus allows us to directly figure out in which direction, and by roughly how much, to change each weight, without having to try all these small changes. The way to do this is by calculating gradients. This is just a performance optimization, we would get exactly the same results by using the slower manual process as well.\n",
    "6. Go back to the step 2, and repeat the process\n",
    "7. Iterate until you decide to stop the training process (for instance, because the model is good enough or you don't want to wait any longer). Generally, you would want to stop the training process when the model stops improving or gets worse\n",
    "\n",
    "These relatively simple steps are the basis for nearly all deep learning models.\n",
    "\n",
    "Calculating gradients relies heavily on derivatives. \n",
    "\n",
    "Derivatives are a way of finding **the instantaneous rate of change** or **the slope** of a function at any given point. A derivative in calculus is a measure of how a function changes as its input changes. It's like the speedometer of a car; it tells you how fast you're going at any point in time. Derivatives calculate the change of a function, not it's value.\n",
    "\n",
    "For example, if `f'(2) = 4`; this means several things:\n",
    "\n",
    "- at `x = 2` the slope of the function `f(x)` is `4`\n",
    "- we can interpret that any small change in `x` around `2` will increase `f(x)` 4 times as fast\n",
    "\n",
    "When we know how a function changes, we know what we need to make its value smaller.\n",
    "\n",
    "One important thing to be aware of is that our function has lots of weights that we need to adjust, so when we calculate the derivative of these weights we won't get back one number, but rather lots of them: a _gradient_ for every weight. But there is nothing mathematically tricky here; you can calculate the derivative with respect to one weight, and treat all the other ones as constant, then repeat that for each other weight. This is how all of the gradients are calculated, for every weight.\n",
    "\n",
    "Thankfully, `PyTorch` can automatically compute the derivative of nearly any function!\n",
    "\n",
    "The gradients only tell us the slope of a function, but they don't tell us how we should adjust our weights. However it gives us useful indications:\n",
    "\n",
    "- if the slope is very large, then that may suggest that we have more adjustments to do\n",
    "- if the slope is very small, then that may suggest that we are close to the optimal value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The notion of _learning rate_\n",
    "\n",
    "The _learning rate_ is the number by which you multiply the gradients in a gradients descent.\n",
    "\n",
    "Deciding how to change our weights based on the values of the gradients is an important part of the deep learning process. Nearly all approaches start with the basic idea of multiplying the gradient by some small number, called the learning rate (LR). The learning rate is often a number between 0.001 and 0.1, although it could be anything.\n",
    "\n",
    "Deciding which learning rate to use is a trial and error process. If you make it too big, your model will diverge, which means it will get worse and worse. But if you make it too small, the model will eventually improve, but it will take forever to converge.\n",
    "\n",
    "The _learning rate_ is a hyperparameter: it controls how much the program adjusts its parameters in response to the feedback it gets. To understand with an analogy:\n",
    "  - imagine a robot trying to learn how to walk\n",
    "  - the learning rate would be the size of the steps the robot takes\n",
    "  - if the steps are too wide, the robot will fall (overcorrecting)\n",
    "  - if the steps are too small, the robot will take a long time to learn and hardly make any progress (undercorrecting)\n",
    "\n",
    "Here is a visual representation of an undercorrecting model:\n",
    "\n",
    "![undercorrecting model](https://raw.githubusercontent.com/fastai/fastbook/823b69e00aa1e1c1a45fe88bd346f11e8f89c1ff//images/chapter2_small.svg)\n",
    "\n",
    "And here are some overcorrecting models examples:\n",
    "\n",
    "![overcorrecting model](https://raw.githubusercontent.com/fastai/fastbook/823b69e00aa1e1c1a45fe88bd346f11e8f89c1ff/images/chapter2_div.svg)\n",
    "\n",
    "![overcorrecting model](https://raw.githubusercontent.com/fastai/fastbook/823b69e00aa1e1c1a45fe88bd346f11e8f89c1ff//images/chapter2_bouncy.svg)\n",
    "\n",
    "... as you can see, the first one makes steps that are too big, resulting in a lousy performance, and the other bounces back and forth because of a step that may be a little too high, this would cause training to be very slow.\n",
    "\n",
    "Adjusting the weights of our model can be then expressed as simply as:\n",
    "\n",
    "```python\t\n",
    "weights -= gradient * lr\n",
    "```\n",
    "\n",
    "This what _stepping the weights_ actually means.\n",
    "\n",
    "We use a substraction here to allow for:\n",
    "\n",
    "- in case the slope is positive, the weight to be decreased\n",
    "- in case the slope is negative, the weight to be increased\n",
    "\n",
    "Remember: our ultimate goal is to minimize the loss."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGD summary\n",
    "\n",
    "Let's summarize a few points here:\n",
    "\n",
    "- The weights of a model can be random (training a model from scratch) or they can come from a pre trained model (transfer learning).\n",
    "- If you train a model from scratch, the first outputs you'll get will probably be pretty bad, because your weights are random.\n",
    "- Also, in case of a pretrained model, the first outputs won't probably be what you want, because the model was trained for a different task. So, the model will need to _learn_ better weights.\n",
    "- To measure the performance of a model, you compare the outputs the model gives you with the targets (the true labels), using a loss function.\n",
    "- We want the output of the loss function to be as low as possible by improving the weights of the model.\n",
    "- For improving the model, you'd want to set aside a few data items that you don't train the model on, called the _validation set_. This is the set that will be used to measure performance.\n",
    "- Figuring out how to change the loss to make it better heavily relies on Calculus and gradients. This is made easy with tools like `PyTorch` .\n",
    "- At each pass of the iterative process that makes the weights better, we use the magnitude of each gradient to tell us how big a step is to take into a better direction. We multiply the gradients by a number called the _learning rate_ to decide each step size.\n",
    "- When the loss does not get any better, we say that the model has _converged_ and we stop the training.\n",
    "\n",
    "Alright, we are ready to apply this to the MNIST dataset now !\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining a MNIST loss function\n",
    "\n",
    "For our digits classifier issue to solve, we already have independent variables (x-axis): these are the images themselves. This means we can put together our training dataset.\n",
    "\n",
    "Let's concatenate all of them into a single tensor.\n",
    "\n",
    "To do this, we'll need to go from a rank-3 tensor of images stacked together to a list of vectors (rank-2 tensor). This can be done using the `view` method of `PyTorch` tensors, as it changes the shape of a tensor without changing its contents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# `torch.cat` concatenates tensors along the first dimension;\n",
    "# then `view` reshapes the concatenated tensor into a rank-2 tensor,\n",
    "# this new tensor has 28*28 columns and a number of rows equal to the number of images in the 2 original tensors;\n",
    "# a 28*28 image is flattened into a 784-element vector\n",
    "train_x = torch.cat([stacked_threes, stacked_sevens]).view(-1, 28*28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's label each image\n",
    "train_y = tensor([1]*len(threes) + [0]*len(sevens)).unsqueeze(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The line of code above:\n",
    "\n",
    "- concatenates 2 tensors of length `len(threes)` and `len(sevens)` respectively\n",
    "- the first elements of this new tensor (`len(threes)`) are set to 0\n",
    "- the last elements of this new tensor (`len(sevens)`) are set to 1\n",
    "- calling `unsqueeze` on a tensor adds an extra dimension to it\n",
    "- we add one extra dimension to match the shape of the images tensor that will be fed to the model\n",
    "- the resulting tensor has a shape of `(n, 1)`, where `n` is the number of images in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([12396, 784]), torch.Size([12396, 1]))"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape,train_y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A `Dataset` in `PyTorch` is an abstract class that represents a collection of data samples.\n",
    "\n",
    "When indexed, a `Dataset` is required to return a tuple of `(x,y)`, where `x` is the input data and `y` is the label.\n",
    "\n",
    "A `Dataset` in `PyTorch` is required to return a tuple of `(x,y)` when indexed. Python provides a `zip` function which, when combined with `list`, provides a simple way to get this functionality. \n",
    "\n",
    "The `zip` function in Python takes two or more iterables and returns a zip object. The zip object is an iterator that produces tuples of corresponding elements from the iterables.\n",
    "\n",
    "```python\n",
    "list(zip([1, 2, 3], [4, 5, 6]))\n",
    "# [(1, 4), (2, 5), (3, 6)]\n",
    "```\n",
    "\n",
    "As you can see, each tuple contains the corresponding elements from the 2 lists.\n",
    "\n",
    "This is how we are going to use it to create our `Dataset` of images and labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([784]), tensor([1]))"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set = list(zip(train_x,train_y))\n",
    "\n",
    "# taking a look at the first element of the dataset,\n",
    "# here, `y` represents the label of the image\n",
    "x,y = training_set[0] \n",
    "x.shape,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now, let's put together our validation set\n",
    "valid_x = torch.cat([valid_3_tens, valid_7_tens]).view(-1, 28*28)\n",
    "valid_y = tensor([1]*len(valid_3_tens) + [0]*len(valid_7_tens)).unsqueeze(1)\n",
    "validation_set = list(zip(valid_x,valid_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.0125],\n",
       "        [-0.5163],\n",
       "        [ 1.7348],\n",
       "        [ 0.0320],\n",
       "        [ 0.9727]], grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's initialize our weights for every pixel with random values\n",
    "\n",
    "# this function returns a tensor of size `size` filled with random values from a normal distribution with a standard deviation of `std`\n",
    "def init_weights(size, std=1.0): return (torch.randn(size)*std).requires_grad_()\n",
    "\n",
    "weights = init_weights((28*28,1))\n",
    "# print a sample of our weights\n",
    "weights[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the goal is to multiply each pixel of the images by a weight value, we should take into account the fact that some pixels will have a value of `0`.\n",
    "\n",
    "This means that the function `weights * pixels` won't be flexible enough for our purpose since it can sometimes result in a value of `0` even if the weight is not `0`. In that case the y-intercept for this weight would be 0 and that's not we want.\n",
    "\n",
    "Now, since the equation of a straight line is `y = wx + b`, we can add a constant `b` to our function to make it more flexible. This is called a _bias_.\n",
    "\n",
    "Together, the _weights_ and the _bias_ are called the _parameters_ of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.2664], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bias = init_weights(1)\n",
    "\n",
    "# we are now able to calculate a prediction for an image,\n",
    "# this is a simple implementation of a linear regression model;\n",
    "# `weights.T` means \"taking the transpose of the weights tensor\",\n",
    "# this is done because we want to multiply the weights by the pixels of the image,\n",
    "# so we turn the `weights` matrix rows into columns and vice versa\n",
    "(train_x[0]*weights.T).sum() + bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While we could use a Python for loop to calculate the prediction for each image, that would be very slow. Because Python loops don't run on the GPU, and because Python is a slow language for loops in general, we need to represent as much of the computation in a model as possible using higher-level functions.\n",
    "\n",
    "In this case, there's an extremely convenient mathematical operation that calculates `w*x` for every row of a matrix: matrix multiplication.\n",
    "\n",
    "In Python, matrix multiplication is represented with the `@` operator. Let's try it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([784, 1])"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12396, 784])"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  1.2664],\n",
       "        [ -9.0091],\n",
       "        [-14.2207],\n",
       "        ...,\n",
       "        [ 16.6940],\n",
       "        [  6.5500],\n",
       "        [  8.0619]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def linear1(xb): return xb@weights + bias\n",
    "preds = linear1(train_x)\n",
    "preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The equation `batch @ weights + bias` is a fundamental equation of any neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting a better accuracy\n",
    "\n",
    "<!-- TODO -->"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
