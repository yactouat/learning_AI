{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RUNS PRETTY QUICKLY ON A GOOD 2023 LAPTOP (i7-11800H, 64GB RAM, RTX 3070 8GB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# running this on Ubuntu\n",
    "# !sudo apt install python3-pip\n",
    "# !pip install fastai"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pre requisites\n",
    "\n",
    "### Median and Mode in Statistics\n",
    "\n",
    "Sure, let's break down these two statistical measures:\n",
    "\n",
    "1. **Median**: The median is the middle value in a dataset when the numbers are sorted in ascending or descending order. If there is an odd number of observations, the median is the middle number. If there is an even number of observations, the median is the average of the two middle numbers. The median can be a more useful measure than the mean (average) when dealing with data that is skewed or has extreme values, as it is not affected by these outliers.\n",
    "\n",
    "2. **Mode**: The mode is the value that appears most frequently in a dataset. A dataset may have one mode, more than one mode, or no mode at all. For example, in the dataset {2, 3, 4, 4, 5}, the mode is 4 because it appears twice, more than any other number. If the data set is {2, 3, 4, 4, 5, 5}, it has two modes (4 and 5), making it a bimodal dataset. In a dataset where no number repeats, such as {1, 2, 3, 4, 5}, there is no mode.\n",
    "\n",
    "In summary, the median and mode are both measures of central tendency, used to understand the distribution of a dataset, but they measure different aspects. The median gives us a mid-point of the data, while the mode indicates the most frequently occurring value(s).\n",
    "\n",
    "#### practical use-case of median\n",
    "\n",
    "Let's consider a real-world scenario in which the median is a more meaningful measure of central tendency: house prices in a neighborhood.\n",
    "\n",
    "Suppose you're a real estate agent or a home buyer interested in the typical price of houses in a particular neighborhood. The homes in this neighborhood vary greatly in price due to differences in size, age, condition, and proximity to local amenities.\n",
    "\n",
    "Here's why the median would be particularly useful in this scenario:\n",
    "\n",
    "1. Let's say there are 101 houses in this neighborhood. To find the median price, you would list all the house prices in ascending order and find the middle value. If there's an even number of houses, the median would be the average of the two middle numbers.\n",
    "\n",
    "2. The median gives you the middle point of house prices, which means that half of the houses are priced below this point and half are priced above it. This can be very useful information for a prospective buyer or a real estate agent to understand the distribution of house prices in that neighborhood.\n",
    "\n",
    "3. One of the advantages of the median in this context is that it is not affected by extremely high or low values (outliers). For instance, if most houses are priced between $200,000 and $300,000, but a few luxury homes are priced at $2,000,000, the mean (average) house price would be significantly higher than what a typical house in the neighborhood costs. However, the median would not be skewed by these few high-end homes, providing a more accurate picture of what a typical buyer might expect to pay.\n",
    "\n",
    "So in this scenario, using the median rather than the mean would provide a more meaningful representation of the central tendency of house prices.\n",
    "\n",
    "#### practical use-case of mode\n",
    "\n",
    "Sure, let's consider an example involving a shoe store to demonstrate a scenario where the mode is meaningful.\n",
    "\n",
    "Suppose you are a store manager for a shoe store. Understanding your sales and customers' preferences is crucial for managing your inventory effectively. \n",
    "\n",
    "One simple piece of data you might be interested in is the most commonly sold shoe size. This is where the mode becomes useful. \n",
    "\n",
    "Here's why:\n",
    "\n",
    "1. If you look at your sales data for the past year, you might have sold shoes in sizes ranging from 5 to 13. To find the mode, you would identify which shoe size appears most frequently in your sales data.\n",
    "\n",
    "2. Suppose you find that size 9 is the mode - it appears more frequently than any other size. This tells you that size 9 shoes are the most commonly sold in your store.\n",
    "\n",
    "3. This information can help guide your inventory decisions. For example, you might want to make sure you order more size 9 shoes than other sizes to meet the demand.\n",
    "\n",
    "In this scenario, the mode provides a meaningful insight that can directly impact business decisions. It's worth noting that while the mean or median shoe size might also be interesting, they would not provide the same level of practical, actionable insight.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python imports\n",
    "from fastai.tabular.all import *\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#3) [Path('/home/yactouat-play/.fastai/data/adult_sample/models'),Path('/home/yactouat-play/.fastai/data/adult_sample/export.pkl'),Path('/home/yactouat-play/.fastai/data/adult_sample/adult.csv')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# downloaded the [Census Income Data Set](https://archive.ics.uci.edu/ml/datasets/Adult)\n",
    "# based on a pre defined constant in fastai\n",
    "# the goal here will to be predict which person will earn more than 50k a year\n",
    "path = untar_data(URLs.ADULT_SAMPLE)\n",
    "# showing, where on the machine the data is stored\n",
    "path.ls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>49</td>\n",
       "      <td>Private</td>\n",
       "      <td>101320</td>\n",
       "      <td>Assoc-acdm</td>\n",
       "      <td>12.0</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>1902</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;=50k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44</td>\n",
       "      <td>Private</td>\n",
       "      <td>236746</td>\n",
       "      <td>Masters</td>\n",
       "      <td>14.0</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>10520</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;=50k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>96185</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;50k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>38</td>\n",
       "      <td>Self-emp-inc</td>\n",
       "      <td>112847</td>\n",
       "      <td>Prof-school</td>\n",
       "      <td>15.0</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Asian-Pac-Islander</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;=50k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>42</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>82297</td>\n",
       "      <td>7th-8th</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Other-service</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;50k</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age          workclass  fnlwgt     education  education-num   \n",
       "0   49            Private  101320    Assoc-acdm           12.0  \\\n",
       "1   44            Private  236746       Masters           14.0   \n",
       "2   38            Private   96185       HS-grad            NaN   \n",
       "3   38       Self-emp-inc  112847   Prof-school           15.0   \n",
       "4   42   Self-emp-not-inc   82297       7th-8th            NaN   \n",
       "\n",
       "        marital-status        occupation    relationship                 race   \n",
       "0   Married-civ-spouse               NaN            Wife                White  \\\n",
       "1             Divorced   Exec-managerial   Not-in-family                White   \n",
       "2             Divorced               NaN       Unmarried                Black   \n",
       "3   Married-civ-spouse    Prof-specialty         Husband   Asian-Pac-Islander   \n",
       "4   Married-civ-spouse     Other-service            Wife                Black   \n",
       "\n",
       "       sex  capital-gain  capital-loss  hours-per-week  native-country salary  \n",
       "0   Female             0          1902              40   United-States  >=50k  \n",
       "1     Male         10520             0              45   United-States  >=50k  \n",
       "2   Female             0             0              32   United-States   <50k  \n",
       "3     Male             0             0              40   United-States  >=50k  \n",
       "4   Female             0             0              50   United-States   <50k  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# having a look at a sample of the data\n",
    "df = pd.read_csv(path/'adult.csv')\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32561"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's see how many rows we have here\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all of the categorical variables of this dataset (such as workclass, education, marital-status, etc.) will have a unique index,\n",
    "# whereas contiguous fields (like age, for instance) will be treated as simple float numbers;\n",
    "# this is what we specify our data loader\n",
    "\n",
    "# `y_names` is the name of the dependent variable (the one we want to predict)\n",
    "dls = TabularDataLoaders.from_csv(path/'adult.csv', path=path, y_names=\"salary\",\n",
    "    cat_names = ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race'],\n",
    "    cont_names = ['age', 'fnlwgt', 'education-num'],\n",
    "    procs = [Categorify, FillMissing, Normalize])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above code, `procs` is a list of data preprocessing steps to be applied to the input data before training the model. \n",
    "\n",
    "- `Categorify` is a preprocessing step that converts categorical variables into numerical representations.\n",
    "- `FillMissing` is a preprocessing step that fills in missing values in the dataset.\n",
    "  - in practice, this means replacing missing value with the median (for continuous fields) or mode (for categorical fields) value of the column.\n",
    "- `Normalize` is a preprocessing step that normalizes the continuous variables (values within a given range) in the dataset to have a mean of 0 and a standard deviation of 1.\n",
    "  - \"Normalization\" in the context of data preprocessing is a technique used to standardize the range of independent variables or features of data (e.g. things that are difficult to compare in place because of their different scales). This can make the dataset easier to work with and can help machine learning algorithms perform better.\n",
    "  - Normalizing a dataset to have a mean of 0 and a standard deviation of 1 is often called \"standardization\" or \"z-score normalization\".\n",
    "    - Mean of 0: When we say that the normalized data has a mean of 0, we mean that if you add up all the values and divide by the number of values (which is how you calculate the mean), the result will be 0. Essentially, the positive and negative numbers balance each other out.\n",
    "    - Standard deviation of 1: The standard deviation is a measure of how spread out the numbers in the data are. If the data is tightly clustered around the mean, the standard deviation is small, and if the data is spread out over a large range of values, the standard deviation is large. When we say the normalized data has a standard deviation of 1, we're saying that the spread of the data has been adjusted so that it corresponds to a certain defined range, one that spreads the value evenly around the mean (the data is said to be `centered`).\n",
    "  - The reason we do this is to put different variables on an equal footing before we run a machine learning algorithm. For example, if you have one variable that is in the range of 1 to 10 and another that is in the range of 1 to 1,000,000, the algorithm might end up giving too much weight to the larger variable simply because of its scale. By standardizing both variables to have a mean of 0 and standard deviation of 1, we ensure they both can have an equal impact on the algorithm's result. In other words, normalization is a way to make different types of data comparable, so that no single type of data overpowers the others when we're trying to find patterns or make predictions.\n",
    "\n",
    "By applying these preprocessing steps, the data is transformed into a format that can be used by the model for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now let's split the data into a training and validation set\n",
    "# we'll use a fixed seed for reproducibility,\n",
    "# this seed will be used for the random number generator that will split the data\n",
    "seed = 42\n",
    "\n",
    "# we take 20% of the data for validation\n",
    "train_idx, valid_idx = train_test_split(range_of(dls.train), test_size=0.2, random_state=seed)\n",
    "\n",
    "# set the new train and validation indices\n",
    "splits = (list(train_idx), list(valid_idx))\n",
    "\n",
    "# update the data loader with the new splits\n",
    "dls.train_idx = splits[0] # type: ignore\n",
    "dls.valid_idx = splits[1] # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.418488</td>\n",
       "      <td>0.395155</td>\n",
       "      <td>0.824939</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.370648</td>\n",
       "      <td>0.363347</td>\n",
       "      <td>0.827856</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.358403</td>\n",
       "      <td>0.350957</td>\n",
       "      <td>0.838759</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.354483</td>\n",
       "      <td>0.352458</td>\n",
       "      <td>0.839373</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.343820</td>\n",
       "      <td>0.348777</td>\n",
       "      <td>0.841984</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.351370</td>\n",
       "      <td>0.347064</td>\n",
       "      <td>0.841063</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# now let's learn !\n",
    "# this learner will infer the loss function based on the earlier specified `y_names` variable\n",
    "learn = tabular_learner(dls, metrics=accuracy) # type: ignore\n",
    "learn.fit_one_cycle(6) # we train the model from scratch here"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, with a few training cycles, we get a decent prediction here !"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
